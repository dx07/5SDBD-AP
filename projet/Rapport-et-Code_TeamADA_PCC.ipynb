{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import setup\n",
    "setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Projet AP : Late Evacuation Planning Problem\n",
    " \n",
    "Team : ADA\n",
    " \n",
    "Team members :\n",
    "- Anaïs Rabary  \n",
    "- Duc Hau Nguyen  \n",
    "- Adrien Mega  \n",
    "\n",
    "Plan :\n",
    "1. Introduction au projet GEO-SAFE\n",
    "2. Evacuation Planning problem\n",
    "3. Generator\n",
    "4. 1ers Résultats  avec la contrainte cumulative\n",
    "5. Conclusion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 :  Introduction projet GEO-SAFE\n",
    "\n",
    "Le but de ce projet est de pouvoir **assister la prise de décision des autorités lors de l'évacuation à grande échelle (de la population) pendant un feu de forêts**. Pour cela, il faut modéliser le problème pour vérifier ensuite que  l'évacuation de la population pendant un feu est bien réalisable. \n",
    "\n",
    "La population se trouve sur des noeuds à évacuer. Dans la \"vraie vie\", il y a 3 catégories de personnes à évacuer : les personnes qui partent tôt, celles qui se réfugient dans un lieu et celles qui restent \"se battre\". Les derniers sont les personnes qui concernent l'objet de la modélisation. Ce sont des personnes qui partent tard.\n",
    "\n",
    "Ce problème d'évacuation est souvent comparé à l'évacuation lors d'innondations. Mais dans ce dernier cas, les modèles sont plus \"simples\" car l'eau évolue toujours de la même façon. Ce n'est pas le cas du feu qui est beaucoup moins prédictible que l'eau. En effet, la propagation d'un feu n'est pas fixe pour une topologie donnée mais évolue en fonction du vent, de la présence de combustibles, ... Donc la méthode d'évacutaion lors de feu a besoin d'être plus robuste pour pouvoir prédire différents scénarios. \n",
    "\n",
    "En plus de minimiser le temps d'évacuation de la population, le but est de maximiser le minimum \"safety margin\" spatial et temporel pondéré par la population, sur chaque segment de route. Il faut donc être le plus loin et le plus rapidement possible du feu.\n",
    "\n",
    "L'équipe ADA s'est appuyée sur le papier *A study of Evacuation Planning for Wildfires* de l'équipe GeoSafe (Christian Artigues, Emmanuel Hebread, Yannick Pencole, Andreas Schutt et Peter Stuckey). La méthode d'optimisation choisie ici est PCC, **programmation par contraintes** avec CP Optimizer.\n",
    "\n",
    "Dans un premier temps, nous présenterons la **modélisation du problème**. Nous intronduirons aussi le **module de génération de données et son exploitation** pour notre problème. Puis nous présenterons notre **résolution pour un simple modèle à l'aide d'une contrainte cummulative**. \n",
    "\n",
    "## Partie 2 : Evacuation Planning Problem\n",
    "\n",
    "Il faut déterminer la date à laquelle l'évacuation commence pour chaque noeud, ainsi que le taux d'évacuation. Le taux d'évacuation est en fait une modélisation du niveau de ressources utilisées par les autorités pour évacuer les gens.  \n",
    "\n",
    "### 2.1 Hypothèses\n",
    "Quelques hypothèses ont été posées par l'équipe GeoSafe :\n",
    "- Les authorités ont déjà identifié des routes accessibles et des points de refuges en sécurité. Chaque sommet à évacuer a donc une seule route d'évacuation. Il y a 1 seul et même point de refuge à atteindre par toute la population a évacuer. Il se peut qu'il y ait une congestion sur un des segment de route partagé par plusieurs points.\n",
    "- Les autorités ont déja estimé le nombre d'habitants à évacuer (la population de ceux qui partent tard).\n",
    "- La modélisation du feu donne une deadline pour chaque segment (date à laquelle le feu arrive).\n",
    "- Une fois que l'évacuation d'un point a commencé, le process ne peut pas être interrompu. Les personnes en cours d'évacuation ne s'arrêtent jamais.\n",
    "- C'est non-préemptif.\n",
    "- Le flux d'évacuation reste constant durant tout le processus d'évacuation.\n",
    "\n",
    "### 2.2 Modélisation \n",
    "Un arbre $G= (\\varepsilon \\cup T \\cup \\{r\\}, A)$ qui représente les routes depuis les sommets à évacuer $\\varepsilon$ vers le refuge $r$ en passant par des noeuds de transit $T$\n",
    "\n",
    "- sur chaque noeud $v\\in\\varepsilon$, il y a $W_{v}$ personnes à évacuer.\n",
    "- Chaque arc alant de $u$ à $u'$, de longueur $l_{uu'}$ a une capacité $q_{u}$.\n",
    "- $H=[0,h]$ représente l'interval de temps pour l'évacuation.\n",
    "Il faut associer chaque $v$ à un réel $s_{v}$ représentant le **retard du préavis d'évacuation** ainsi qu'a une courbe de réponse $\\phi_{v}$ décrivant le **flow d'évacuation** d'un noeud $v$ a un taux $\\phi_{v}(t)$. Avant $s_{v}$ le taux $\\phi_{v}$ est à 0.\n",
    "$$\\int_{0}^{H}\\phi_{v}(t)dt=w_{v} $$\n",
    "Le flow $\\phi_u$ pour n'importe quel arc $u-v$ à n'importe quel moment noeud : \n",
    "$$\\phi_u(t)=\\sum_{v\\in descendants(u)} \\phi_{v}(t-l_{uv}-s_{v})$$  \n",
    "\n",
    "On peut aussi le réécrire :\n",
    "$$\\phi_u(t)=\\sum_{V\\in descendants(u),\\: s_v+l_{uv}\\le t \\lt s_v+l_{uv}+\\frac{w_v}{h_v}} h_v$$  \n",
    "\n",
    "Ici, $\\phi_v$ est une courbe de réponse simple. Le flux sortant $\\phi_v$ est une variable de décision continue et qui reste constante penant le process d'évacuation.\n",
    "On note aussi :\n",
    "$$ \\phi_v = h_v\\: during\\: [s_v,e_v]\\: with\\: e_v=s_v + \\frac{w_v}{h_v}$$\n",
    "\n",
    "\n",
    "- Il y a une tâche pour chaque noeud à évacuer. Pour chaque tâche, on a un **taux constant d'évacuation** $\\phi_v \\le q_{v}$ et une **heure de début d'évacuation** $s_{v}\\in [0, H-\\frac{w_v}{h_v}]$\n",
    "\n",
    "**CONTRAINTES** :   \n",
    "Il n'y a qu'un seul type de contraintes pour éviter les bouchons (donc éviter d'avoir un flux plus grand que la capacité d'un arc) : $\\phi_v \\le q_{v}$\n",
    "\n",
    "**OBJECTIF** :  \n",
    "Chaque noeud de transit a une date au plus tard (due date) $d_u$, date à partir de laquelle la route n'est plus en sécurité (à cause du feu). L'objectif est donc de minimiser l'écart de temps maximal entre lequel la population quitte $u$ et la due date $d_u$.\n",
    "$$\\min \\max_{u\\in T,v\\in descendants(u)} s_v + \\frac{h_v}{w_w} + l_{uv} - d_u$$\n",
    "\n",
    "Cette fonction objectif se simplifie en \n",
    "$$\\min \\max_{v\\in\\varepsilon} s_v + \\frac{h_v}{w_w} - d_v$$\n",
    "avec $d_v=\\min_{u\\in T}\\{d_u-l_{uv}\\}$\n",
    "\n",
    "**OBSERVATION**:   \n",
    "Pour chaque noeud de transit $u$ et $u'$, avec $u'$ déscendant de $u$ un bouchon sur $u'$ entraine un bouchon sur $u$. Donc, il ne faut checker l'occurance de bouchons uniquement si la capacité de $u$ est supérieur à la capacité de sons ascendant $v$ ( $\\forall v \\in p'(u),q_u \\gt q_v$ )  \n",
    "\n",
    "**SIMPLIFICATION**:     \n",
    "Sur un chemin de $u$ vers $u'$ sans branches, on garde la capacité de l'arc minimum. \n",
    "Par exemple, avec c'<c, on garde donc la capacité c' :  \n",
    "            S5  `  \n",
    "```\n",
    "S1 ___ S2 ___ S3 ___ S4  \n",
    "     c     c'  |    \n",
    "               S5  \n",
    "```\n",
    "   \n",
    "```\n",
    "S1 ___ S2 ___ S3 ___ S4  \n",
    "     c'     c'  |    \n",
    "               S5  \n",
    "```\n",
    "\n",
    "Ci-après le code de cette modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.cp.model import CpoModel\n",
    "from docplex.cp.model import *\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_duc import setup\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geosafe_model(l, q, eps, r, W, H, d):\n",
    "    '''       \n",
    "    Int  Matrix l: length path from i to j = G.l[i,j]. No path ij <--> G.l[i,j] = 0\n",
    "    Int  Array  q: capacity of node i <--> G.q[i]\n",
    "    Bool Array  eps: evacuation node \n",
    "    Bool Array  r: safe node\n",
    "    Int  Array  W: initial population at node i <--> W[i]\n",
    "    Int         H : Time span\n",
    "    Int  Array  d: deadline to leave the node\n",
    "    '''\n",
    "    \n",
    "    nb_node = q.shape[0]\n",
    "    nodes = np.arange(nb_node) # id nodes, i.e [1,2,3,4, ...]\n",
    "    total_population = np.sum(W)\n",
    "\n",
    "    mdl = CpoModel(name='geosafe')\n",
    "    \n",
    "    # == Output ==\n",
    "    # starting date\n",
    "    s = np.array( mdl.integer_var_list(nb_node, min=0, max = H, name=\"s\") )\n",
    "        \n",
    "    # evacuation rate aka. height of package\n",
    "#     h = np.array([\n",
    "#         mdl.integer_var(name='phi[%d]')%(i+1), min=0, max = W[i] for i in range(nb_nodes)\n",
    "#     ])\n",
    "    h = np.array( mdl.integer_var_list(nb_node, min=0, max = 100, name=\"h\") )\n",
    "\n",
    "    # == Intermediate ==\n",
    "    # node flow of population\n",
    "    phi = np.matrix([\n",
    "            [ \n",
    "                mdl.integer_var(name='phi[%d,%d]'%(i+1,j)) for j in range(H) \n",
    "            ] for i in range(nb_node)\n",
    "        ])\n",
    "    \n",
    "    # ending date (leaving time) of node\n",
    "    e = np.array( mdl.integer_var_list(nb_node, min=0, max = 150, name= \"e\") )\n",
    "    \n",
    "    for v in range(nb_node):\n",
    "        if eps[v]:\n",
    "            mdl.add(\n",
    "                e[v] == s[v] + W[v]/h[v]\n",
    "            )\n",
    "    \n",
    "    # == Constraints ==\n",
    "    \n",
    "    # Time long enough to evacuate (additional)\n",
    "    for v in nodes[eps]:\n",
    "        mdl.add( h[v] * H >= W[v] )\n",
    "    \n",
    "    # evacuate everyone in evacuation node (???)\n",
    "    # has been moved above\n",
    "    \n",
    "    # Flow at a node u = sum from all of its leaves node epsilon\n",
    "#     mdl.add(\n",
    "#         phi[u, t] == np.sum( phi[u, t - l[u,v] - s[eps]] ) \\\n",
    "#             for t in range(H)                                  \\\n",
    "#             for v in np.where(eps)                           \\\n",
    "#             for u in np.where(t)                             \n",
    "#     )\n",
    "\n",
    "    # simplified version\n",
    "#     for u in nodes[np.where(np.logical_and(np.invert(eps), np.invert(r)))]:\n",
    "        \n",
    "#         for t in range(H):\n",
    "            \n",
    "#             v_arrays = nodes[np.where(\n",
    "#                                 np.logical_and(\n",
    "#                                     np.logical_and(\n",
    "#                                         np.logical_and(\n",
    "#                                             eps,\n",
    "#                                             l[:,u] > 0, \n",
    "#                                         ),\n",
    "#                                         s + l[:,u] <= t,\n",
    "#                                     ),\n",
    "#                                     t <= e + l[:, u]\n",
    "#                                 )\n",
    "#                             )[1]]\n",
    "            \n",
    "#             mdl.add(\n",
    "#                 phi[u, t] == mdl.sum(h[v] for v in v_arrays)\n",
    "#             )\n",
    "\n",
    "#     for u in nodes[eps]:\n",
    "#         mdl.add(\n",
    "#             mdl.sum(phi[u, t] for t in range(H)) == h[u]\n",
    "#         )\n",
    "\n",
    "    for t in range(H):\n",
    "\n",
    "        # Flow at epsilon should be h during the evacutation period\n",
    "        for u in nodes[eps]:\n",
    "            mdl.add( \n",
    "                phi[u, t] == h[u]\n",
    "            )\n",
    "            \n",
    "        \n",
    "        # Flow at a node u = sum from all of its leaves node epsilon\n",
    "        for u in nodes[np.where(np.logical_and(np.invert(eps), np.invert(r)))]:\n",
    "            mdl.add(\n",
    "                phi[u, t] == mdl.sum(h[v] for v in nodes[eps] if l[v,u] != math.inf and s[v] + l[v,u] <= t and t <= e[v] + l[v,u])\n",
    "            )\n",
    "    \n",
    "    # Flow at a node does not excess capacity of arc\n",
    "    for t in range(H):\n",
    "        for u in nodes:\n",
    "            mdl.add(\n",
    "                phi[u,t] <= q[u]\n",
    "            )\n",
    "            \n",
    "    # Objective\n",
    "#     mdl.add(\n",
    "#         minimize(mdl.max(s[eps] + h[eps]/W[eps] - d[eps]))\n",
    "#     )\n",
    "    mdl.add(\n",
    "        minimize(mdl.max(s[u] + W[u]/h[u] - d[u] for u in nodes[eps] ))\n",
    "    )\n",
    "    \n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 Utilisation des contraintes cumulatives\n",
    "Une première approche se fait avec des contraintes cumulatives simples.     \n",
    "\n",
    "**NOTATION** :   \n",
    "Pour une variable $x$, $\\bar{x}$ signifie la plus grande valeur de x et $\\underline{x}$, la plus petite valeur de x. \n",
    "\n",
    "Si on prend une selection de **tâches** $J$ avec une **heure de départ** $s_{i} \\in [\\underline{s_i}, \\bar{s_i}]$, avec une **durée de process** $p_i \\in [\\underline{p_i},\\bar{p_i}]$, une **hauteur** $h_i \\in [\\underline{h_i}, \\bar{h_i}]$ et une **resource** $r$ avec une **capacité constante** $q_r$, on défini la contrainte cumulative comme :\n",
    "$$ \\sum_{i\\in J|s_i\\le t\\le s_i+p_i} h_i \\le q_r, \\forall t\\in H$$\n",
    "\n",
    "Donc pour modéliser le problème, il suffit d'associer une tâche $v$ à chaque noeud à évacuer ($v \\in \\varepsilon$), avec une hauteur $h_v \\in ]0, q_v]$, avec une heure de départ $ s_v \\in [0, H-\\frac{w_v}{q_v}]$, une heure de \"complétion\" $e_v \\in [\\frac{w_v}{q_v}, H]$. Puis il faut dupliquer et transformer cette tâche pour chaque arc critique de transit jusqu'au point de refuge. On note $i_{uv}$ la duplication du noeud $v$ sur l'arc critique $u$.\n",
    "\n",
    "On a donc :\n",
    "$$cumulative((s_{i_{uv}}, e_{i_{uv}} - s_{i_{uv}}, h_{i_{uv}})_{v\\in L(u)}, q_u) \\forall u \\in T $$\n",
    "$$w_v=h_v(e_v-s_v) \\forall v \\in \\varepsilon$$\n",
    "$$s_{i_{uv}} = s_v +l_{uv} \\forall u\\in T, \\forall v \\in L(u)$$\n",
    "$$e_{i_{uv}} = e_v +l_{uv} \\forall u\\in T, \\forall v \\in L(u)$$\n",
    "$$h_{i_{uv}} = h_v \\forall u\\in T, \\forall v \\in L(u)$$\n",
    "\n",
    "Le problème avec les contraintes cumulatives \"classiques\" c'est qu'elles ne considèrent que les bornes inférieurs des domaines de solutions possibles. (*cf.exemple p7 de l'article*). Elles ne permettent pas de raisonner avec l'énergie totale de chaque tâche.\n",
    "\n",
    "Des évolutions ont été proposées par l'équipe GeoSafe mais n'ont pas été étudiées ici.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "**NOTE** : Le code associé à cette modélisation se trouve en partie 4 où sont détaillés les 1ers résultats\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 :  Generator \n",
    "Generator est une instance qui permet de générer aléatoirement un réseau de routes et de propager un simple model de feu. Les données générées prennent en compte des propagations de contraintes qu'il convient d'expliquer et de comprendre.\n",
    " \n",
    "### 3.1 Install module\n",
    " Pour générer les données utilisées ensuite dans le projet, il faut utiliser le générateur du projet evacsim présent sur le git https://github.com/ehebrard/evacsim\n",
    " Il faut l'utiliser avec python 2 et avoir installé decorator et networkx.\n",
    " Note : il faut un dossier data dans le projet. C'est dans ce dossier que seront déposées les données générées.  \n",
    " \n",
    " ***\n",
    " \n",
    " Commande pour installer :  \n",
    " `python setup.py install --user`\n",
    " \n",
    " Les commandes pour générer :  \n",
    " `python generator.py --road test --printroad`  \n",
    " `python generator.py test --evacuation --printfire --seed 10`\n",
    " \n",
    " NOTE : avec la commande : `python generator.py --road test --evacuation --printfire --seed 10 --printevac`, on peut voir la route d'évacuation  \n",
    " \n",
    " ***  \n",
    " \n",
    " Pour générer une nouvelle instance de feu, il suffit de changer le paramètre seed.\n",
    " \n",
    " ### 3.2 Modélisation données générées\n",
    " FORMAT :\n",
    " n m population_1 maximum_rate_1 duedate_1 ... population_n maximumrate_n duedate_n capacity_1 k_1 i_1_1 offset_i_1_1 ... i_k_1 offset_i_k_1 ... capacity_m k_m i_1_m offset_i_1_m ... i_k_m offset_i_k_m\n",
    " \n",
    "- **n**, le nombre de noeuds à évacuer\n",
    "- **m**, le nombre d'arcs de transit pertinents (les arcs critiques)\n",
    "- **Population_i**, population du noeud i a évacuer.\n",
    "- **Maximum_rate_i**, taux max de personnes pouvant être évacuées en même temps\n",
    "- **duedate_i**, Date à laquelle le noeud doit être évacué\n",
    "- **capacity_y**, la capacité de l'arc de transit y\n",
    "- **k_y**, le nombre de groupes de population transitant par cet arc\n",
    "- **offset_i_x_y**, date à laquelle la population du groupe i_x_y atteind cet arc si elle part à t=0\n",
    "\n",
    "EXEMPLE :   \n",
    "- l1 : `10 8`  \n",
    "10 zones à évacuer avec 8 arcs à utiliser pour évacuer les zones  \n",
    "- l2 : `1677 70 66`   \n",
    "sur le sommet 1, 1677 personnes à évacuer, par pacquets de 70, avant la date 66  \n",
    "- l3 : `4161 70 40`  \n",
    "- l4 : `3817 70 36`  \n",
    "- l5 : `3745 70 92`  \n",
    "- l6 : `1379 72 126`   \n",
    "- l7 : `3359 71 115`  \n",
    "- l8 : `893 72 120`  \n",
    "- l9 : `463 72 54`  \n",
    "- l10: `4368 212 86`  \n",
    "- l11: `4987 70 44`  \n",
    "Sommet 10  \n",
    "- l12: `74 2 3 20 6 8`  \n",
    "Arc 1, capacité de 74 personnes, Nombre de Groupes transitant par cet arc(2), puis lire par tuple de 2 (3,20) : 3, num du groupe concerné, 20, date au plus tôt à laquelle la population peut partir si il part à t=0. Cela veut donc dire que si le groupe 3 part a t=4, il pourra traverser l'arc 1 à partir de t=24.(6,8).  \n",
    "- l13: `74 4 2 1 5 2 7 4 9 2`  \n",
    "arc2, capacité74 personnes, 4 groupes possibles puis (2,1), (5,2), (7,4), (9,2)  \n",
    "- l13: `206 8 0 13 1 15 2 16 4 14 5 17 7 19 8 9 9 17`  \n",
    "- l14: `72 2 0 2 1 4`  \n",
    "- l15: `203 10 0 33 1 35 2 36 3 40 4 34 5 37 6 28 7 39 8 29 9 37`  \n",
    "- l16: `72 5 2 4 4 2 5 5 7 7 9 5`  \n",
    "- l17: `72 2 7 3 9 1`  \n",
    "- l18: `138 7 0 8 1 10 2 11 4 9 5 12 7 14 9 12`  \n",
    "Arc 8 capacité de 138 personnes, ...    \n",
    "\n",
    "Ci-après 2 images représentant les données des routes, du feu et des chemins d'évacuation générées.  \n",
    "**NOTE IMPORTANTE** : les couleurs des arcs correspondent à la capacité de la route.\n",
    "\n",
    "<div class=\"row\" style=\"margin-top: 10px\">\n",
    "    <div class=\"col-md-offset-0 col-md-3\">\n",
    "        <img src=\"evacsim-master/image_Routes_Anais/routeFire.png\" style=\"margin-right: 0; width: 400px;\" />\n",
    "    </div>  \n",
    "    <div class=\"col-md-offset-0 col-md-3\">\n",
    "        <img src=\"evacsim-master/image_Routes_Anais/routeEvacuation.png\" style=\"margin-right: 0; width: 300px;\" />\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Récupération des données générées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import networkx as nx\n",
    "from docplex.cp.model import CpoModel\n",
    "from docplex.cp.model import *\n",
    "\n",
    "# Comme on ne peut pas définir la longueur d'un arc à partir des fichiers générés ...\n",
    "VALEUR_ARBITRAIRE_ARC_SORTIE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une première fonction parse le fichier graphe écrit par le générateur pour en récupérer le contenu.\n",
    "Ces données sont simplement retournées sous forme de listes (une pour les zones, une pour les arcs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4455, 70, 68]\n",
      "[509, 70, 22]\n",
      "[4584, 71, 128]\n",
      "[2902, 71, 122]\n",
      "[2808, 71, 84]\n",
      "[2744, 70, 22]\n",
      "[3982, 3982, 50]\n",
      "[1471, 70, 122]\n",
      "[1783, 71, 22]\n",
      "[358, 70, 68]\n",
      "[71, [[1, 0], [8, 0]]]\n",
      "[224, [[2, 17], [4, 35], [5, 30]]]\n",
      "[70, [[1, 3], [6, 3], [8, 3]]]\n",
      "[132, [[4, 29], [5, 24]]]\n",
      "[132, [[0, 0], [3, 8], [9, 0]]]\n",
      "[249, [[0, 18], [1, 23], [2, 30], [3, 26], [4, 48], [5, 43], [6, 23], [8, 23], [9, 18]]]\n",
      "[132, [[3, 8], [9, 0]]]\n",
      "[146, [[0, 1], [1, 6], [3, 9], [6, 6], [8, 6], [9, 1]]]\n"
     ]
    }
   ],
   "source": [
    "def read_evac(filename):\n",
    "    \n",
    "    with open(filename,\"r\") as file:\n",
    "        content = file.readlines()\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        \n",
    "        nbzones, nbarcs = content[0].split(\" \")\n",
    "        content.remove(content[0])\n",
    "    \n",
    "        lineszones = content[0:int(nbzones)]\n",
    "        linesarcs  = content[int(nbzones):int(nbzones)+int(nbarcs)]\n",
    "        \n",
    "        E = []\n",
    "        \n",
    "        for line in lineszones:\n",
    "            personnes, paquets, datemax = line.split(\" \")\n",
    "            E.append([int(personnes),int(paquets),int(datemax)])\n",
    "            \n",
    "        A = []\n",
    "        \n",
    "        for line in linesarcs:\n",
    "            \n",
    "            content = line.split(\" \")\n",
    "            capacite = content[0]\n",
    "            content = content[2:]\n",
    "            \n",
    "            groups = []\n",
    "            \n",
    "            for i in range(0,len(content),2):\n",
    "                numgroupe = content[i]\n",
    "                datemax = content[i+1]\n",
    "                \n",
    "                groups.append([int(numgroupe),int(datemax)])\n",
    "                \n",
    "            A.append([int(capacite),groups])\n",
    "            \n",
    "        return E,A\n",
    "        \n",
    "        \n",
    "# import os\n",
    "# os.listdir()\n",
    "\n",
    "E,A = read_evac(\"evacsim-master/data/test_10_25_2_10.evac\")\n",
    "\n",
    "print(*E, sep = \"\\n\")\n",
    "print(*A, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une lecture et un réarrangement sont ensuite appliqués afin de déduire et regrouper les données qui seront utiles à notre modèle de résolution. Ces données sont restituées sous la forme d'une liste plus complexe.\n",
    "\n",
    "Après avoir lu les propriétés de chaque sommet à évacuer, les arcs sont parcourus et ajoutés à la liste des arcs d'un sommet à évacuer. Les arcs sont ajoutés dans l'ordre de parcours.\n",
    "\n",
    "La dernière étape de cette fonction consiste à identifier les sommets intermédiaires entre les arcs, ainsi que le(s) sommet(s) de sûreté. Cette étape nous permet d'obtenir plusieurs propriétés des arcs que nous n'avions pas jusque là, comme le sommet d'origine / d'arrivée ou le temps de parcours d'un arc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " [\n",
      "  [\n",
      "   [\n",
      "    0,\n",
      "    4455,\n",
      "    70,\n",
      "    68,\n",
      "    64,\n",
      "    [\n",
      "     [\n",
      "      4,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      1\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      18\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ],\n",
      "   [\n",
      "    1,\n",
      "    509,\n",
      "    70,\n",
      "    22,\n",
      "    8,\n",
      "    [\n",
      "     [\n",
      "      0,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      2,\n",
      "      3\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      6\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      23\n",
      "     ]\n",
      "    ],\n",
      "    71\n",
      "   ],\n",
      "   [\n",
      "    2,\n",
      "    4584,\n",
      "    71,\n",
      "    128,\n",
      "    65,\n",
      "    [\n",
      "     [\n",
      "      1,\n",
      "      17\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      30\n",
      "     ]\n",
      "    ],\n",
      "    224\n",
      "   ],\n",
      "   [\n",
      "    3,\n",
      "    2902,\n",
      "    71,\n",
      "    122,\n",
      "    41,\n",
      "    [\n",
      "     [\n",
      "      4,\n",
      "      8\n",
      "     ],\n",
      "     [\n",
      "      6,\n",
      "      8\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      9\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      26\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ],\n",
      "   [\n",
      "    4,\n",
      "    2808,\n",
      "    71,\n",
      "    84,\n",
      "    40,\n",
      "    [\n",
      "     [\n",
      "      3,\n",
      "      29\n",
      "     ],\n",
      "     [\n",
      "      1,\n",
      "      35\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      48\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ],\n",
      "   [\n",
      "    5,\n",
      "    2744,\n",
      "    70,\n",
      "    22,\n",
      "    40,\n",
      "    [\n",
      "     [\n",
      "      3,\n",
      "      24\n",
      "     ],\n",
      "     [\n",
      "      1,\n",
      "      30\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      43\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ],\n",
      "   [\n",
      "    6,\n",
      "    3982,\n",
      "    3982,\n",
      "    50,\n",
      "    1,\n",
      "    [\n",
      "     [\n",
      "      2,\n",
      "      3\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      6\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      23\n",
      "     ]\n",
      "    ],\n",
      "    70\n",
      "   ],\n",
      "   [\n",
      "    7,\n",
      "    1471,\n",
      "    70,\n",
      "    122,\n",
      "    22,\n",
      "    [\n",
      "     [\n",
      "      8,\n",
      "      0\n",
      "     ]\n",
      "    ],\n",
      "    null\n",
      "   ],\n",
      "   [\n",
      "    8,\n",
      "    1783,\n",
      "    71,\n",
      "    22,\n",
      "    26,\n",
      "    [\n",
      "     [\n",
      "      0,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      2,\n",
      "      3\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      6\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      23\n",
      "     ]\n",
      "    ],\n",
      "    70\n",
      "   ],\n",
      "   [\n",
      "    9,\n",
      "    358,\n",
      "    70,\n",
      "    68,\n",
      "    6,\n",
      "    [\n",
      "     [\n",
      "      4,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      6,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      1\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      18\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ]\n",
      "  ],\n",
      "  [\n",
      "   [\n",
      "    10,\n",
      "    146\n",
      "   ],\n",
      "   [\n",
      "    11,\n",
      "    249\n",
      "   ],\n",
      "   [\n",
      "    13,\n",
      "    70\n",
      "   ]\n",
      "  ],\n",
      "  [\n",
      "   [\n",
      "    12,\n",
      "    null\n",
      "   ]\n",
      "  ]\n",
      " ],\n",
      " [\n",
      "  [\n",
      "   0,\n",
      "   71,\n",
      "   1,\n",
      "   13,\n",
      "   3\n",
      "  ],\n",
      "  [\n",
      "   1,\n",
      "   224,\n",
      "   2,\n",
      "   11,\n",
      "   13\n",
      "  ],\n",
      "  [\n",
      "   2,\n",
      "   70,\n",
      "   13,\n",
      "   10,\n",
      "   3\n",
      "  ],\n",
      "  [\n",
      "   3,\n",
      "   132,\n",
      "   4,\n",
      "   2,\n",
      "   6\n",
      "  ],\n",
      "  [\n",
      "   4,\n",
      "   132,\n",
      "   0,\n",
      "   10,\n",
      "   1\n",
      "  ],\n",
      "  [\n",
      "   5,\n",
      "   249,\n",
      "   11,\n",
      "   12,\n",
      "   1\n",
      "  ],\n",
      "  [\n",
      "   6,\n",
      "   132,\n",
      "   3,\n",
      "   10,\n",
      "   1\n",
      "  ],\n",
      "  [\n",
      "   7,\n",
      "   146,\n",
      "   10,\n",
      "   11,\n",
      "   17\n",
      "  ],\n",
      "  [\n",
      "   8,\n",
      "   Infinity,\n",
      "   7,\n",
      "   12,\n",
      "   1\n",
      "  ]\n",
      " ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def graph2list(filename):\n",
    "    \n",
    "    E,A = read_evac(\"evacsim-master/data/test_10_25_2_10.evac\")\n",
    "    \n",
    "    ########################## TRAITEMENT DES SOMMETS ##########################\n",
    "    \n",
    "    new_E = [] # Ensemble de sommets à évacuer\n",
    "    \n",
    "    for i_k in range(len(E)):\n",
    "        w_k, h_k, d_k = E[i_k]\n",
    "        p_k = math.ceil(w_k / h_k)\n",
    "        A_k = []\n",
    "        q_k = None\n",
    "        \n",
    "        k = [\n",
    "            i_k,  # Identifiant du sommet\n",
    "            w_k,  # Nombre de personnes à évacuer\n",
    "            h_k,  # Taux d'évacuation d'un sommet\n",
    "            d_k,  # Date à laquelle le sommet crame\n",
    "            p_k,  # Durée d'évacuation d'un sommet\n",
    "            A_k,  # Liste des sommets pour le chemin d'évacuation\n",
    "            q_k,  # Capacité d'un sommet\n",
    "        ]\n",
    "        \n",
    "        new_E.append(k)\n",
    "        \n",
    "    ########################## TRAITEMENT DES ARCS ##########################\n",
    "    \n",
    "    new_A = []\n",
    "    \n",
    "    for i_e in range (len(A)):\n",
    "        c_e, groups = A[i_e]\n",
    "        in_e = None\n",
    "        out_e = None\n",
    "        l_e = None\n",
    "\n",
    "        for i_k, b_e in groups:\n",
    "            \n",
    "            e = [    # Arc d'un chemin d'évacuation d'un sommet\n",
    "                i_e, # Identifiant de l'arc\n",
    "                b_e, # Date min de passage\n",
    "            ]\n",
    "            \n",
    "            k = new_E[i_k]\n",
    "            A_k = k[5]\n",
    "            \n",
    "            if len(A_k) == 0:\n",
    "                A_k.append(e)\n",
    "            else:\n",
    "                added = False\n",
    "                for i in range (len(A_k)):\n",
    "                    if A_k[i][1] > e[1]:\n",
    "                        A_k.insert(i,e)\n",
    "                        added = True\n",
    "                if added == False:\n",
    "                    A_k.append(e)\n",
    "            \n",
    "            k[5] = A_k\n",
    "            new_E[i_k] = k\n",
    "\n",
    "        e = [\n",
    "            i_e,     # Identifiant de l'arc\n",
    "            c_e,     # Capacité de l'arc en personnes par unité de temps\n",
    "            in_e,    # Identifiant du sommet entrant\n",
    "            out_e,   # Identifiant du sommet sortant\n",
    "            l_e,     # Longueur de l'arc\n",
    "        ]\n",
    "        \n",
    "        new_A.append(e)\n",
    "        \n",
    "    ####################### IDENIFICATION DES SOMMETS #######################\n",
    "    \n",
    "    # Cette partie va servir à trouver et compléter la liste des sommets\n",
    "    # intermédiaires et de sortie, tout en complétant les in/out des arcs\n",
    "        \n",
    "    new_T = [] # Ensemble de sommets de transfert\n",
    "    new_S = [] # Ensemble de sommets séurisés\n",
    "    \n",
    "    k_sommets = len(new_E)\n",
    "    k_arcs = []\n",
    "    \n",
    "    for k in new_E:\n",
    "        A_k = k[5]\n",
    "        parcours = k[0]\n",
    "        for i in range (len(A_k)):\n",
    "            e = new_A[A_k[i][0]]\n",
    "             \n",
    "            #On ajoute la capacité au sommet\n",
    "            if parcours < len(new_E):\n",
    "\n",
    "                #C'est un noeud de départ\n",
    "                if new_E[parcours][6] == None or new_E[parcours][6] > e[1]:\n",
    "                    new_E[parcours][6] = e[1]\n",
    "                    \n",
    "            else:\n",
    "    \n",
    "                #C'est un noeud intermédiaire\n",
    "                for j in range (len(new_T)):\n",
    "                    if new_T[j][0] == parcours:\n",
    "                        if new_T[j][1] == None or new_T[j][1] > e[1]:\n",
    "                            new_T[j][1] = e[1]\n",
    "                            \n",
    "            \n",
    "            if e[0] in k_arcs:\n",
    "                \n",
    "                #Arc connu donc rien à faire\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                #On ajoute le sommet d'entrée de l'arc\n",
    "                e[2] = parcours\n",
    "                \n",
    "                #On ajoute l'arc aux arc parcourus\n",
    "                k_arcs.append(e[0])\n",
    "                \n",
    "                #Contrôle de l'arc suivant\n",
    "                if i+1 < len(A_k):\n",
    "\n",
    "                    #Il y a bien un arc suivant, on a affaire à un sommet intermédiaire\n",
    "                    e_suiv = new_A[A_k[i+1][0]]\n",
    "                    \n",
    "                    #On peut donc connaître la longueur de l'arc\n",
    "                    e[4] = A_k[i+1][1] - A_k[i][1]\n",
    "\n",
    "                    if e_suiv[0] in k_arcs:\n",
    "\n",
    "                        #Arc connu donc on connait son entrée, donc celui de sortie de l'arc actuel\n",
    "                        e[3] = e_suiv[2]\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        #Arc inconnu donc on a découvert un nouveau sommet intermédiaire\n",
    "                        e[3] = k_sommets\n",
    "                        new_T.append([k_sommets,None])\n",
    "                        k_sommets += 1\n",
    "\n",
    "                    #On prépare le sommet de départ pour le prochain arc\n",
    "                    parcours = e[3]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    #Pas d'arc suivant donc on a atteint un sommet de sécurité\n",
    "                    e[3] = k_sommets\n",
    "                    new_S.append([k_sommets,None])\n",
    "                    k_sommets += 1\n",
    "                    \n",
    "                    #On ne peut donc pas connaître la longueur de l'arc, on la met arbitraitement à 1\n",
    "                    e[4] = VALEUR_ARBITRAIRE_ARC_SORTIE\n",
    "                        \n",
    "                #Mise à jour de e\n",
    "                new_A[e[0]] = e\n",
    "                \n",
    "    # TODO Bug sur le sommet 3 et arc 6 (qui a la même date au plus tôt que l'arc 4)\n",
    "    # On fait le choix de l'ignorer pour le moment, on a quand même un graphe utilisable\n",
    "    \n",
    "    ####################### CAS DES SOMMETS SANS ARCS  #######################\n",
    "            \n",
    "    for k in new_E:\n",
    "        A_k = k[5]\n",
    "        if len(A_k) == 0:\n",
    "            \n",
    "            #Nouvel arc pour relier le sommet\n",
    "            e = [\n",
    "                len(new_A), # Identifiant de l'arc\n",
    "                math.inf,   # Capacité de l'arc en personnes par unité de temps\n",
    "                k[0],       # Identifiant du sommet entrant\n",
    "                new_S[0][0],      # Identifiant du sommet sortant\n",
    "                VALEUR_ARBITRAIRE_ARC_SORTIE,        # Longueur de l'arc\n",
    "            ]\n",
    "            \n",
    "            A_k.append([e[0],0])\n",
    "            new_A.append(e)\n",
    "    \n",
    "    \n",
    "    ########################## TRAITEMENT DU GRAPHE ##########################\n",
    "    \n",
    "    X = [       # Ensemble des sommets du graphe\n",
    "        new_E,  # Ensemble de sommets à évacuer\n",
    "        new_T,  # Ensemble de sommets de transfert\n",
    "        new_S,  # Ensemble de sommets séurisés\n",
    "    ]\n",
    "    \n",
    "    G = [       # Notre graphe\n",
    "        X,      # Ensemble des sommets du graphe\n",
    "        new_A,  # Ensemble des arêtes du graphe\n",
    "    ]\n",
    "    \n",
    "    return G\n",
    "\n",
    "G_list = graph2list(\"projet/evacsim-master/data/test_10_25_2_10.evac\")\n",
    "\n",
    "print(json.dumps(G_list, indent=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, les données sont extraites pour générer le graphe qui sera donné en entrée de notre modèle de résolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, {'W': 4455, 'd': 68, 'eps': True, 'r': False, 'q': 132}), (1, {'W': 509, 'd': 22, 'eps': True, 'r': False, 'q': 71}), (2, {'W': 4584, 'd': 128, 'eps': True, 'r': False, 'q': 224}), (3, {'W': 2902, 'd': 122, 'eps': True, 'r': False, 'q': 132}), (4, {'W': 2808, 'd': 84, 'eps': True, 'r': False, 'q': 132}), (5, {'W': 2744, 'd': 22, 'eps': True, 'r': False, 'q': 132}), (6, {'W': 3982, 'd': 50, 'eps': True, 'r': False, 'q': 70}), (7, {'W': 1471, 'd': 122, 'eps': True, 'r': False, 'q': inf}), (8, {'W': 1783, 'd': 22, 'eps': True, 'r': False, 'q': 70}), (9, {'W': 358, 'd': 68, 'eps': True, 'r': False, 'q': 132}), (10, {'W': 0, 'd': 0, 'eps': False, 'r': False, 'q': 146}), (11, {'W': 0, 'd': 0, 'eps': False, 'r': False, 'q': 249}), (13, {'W': 0, 'd': 0, 'eps': False, 'r': False, 'q': 70}), (12, {'W': 0, 'd': 0, 'eps': False, 'r': True, 'q': inf})]\n",
      "[(1, 13, {'l': 3}), (2, 11, {'l': 13}), (13, 10, {'l': 3}), (4, 2, {'l': 6}), (0, 10, {'l': 1}), (11, 12, {'l': 1}), (3, 10, {'l': 1}), (10, 11, {'l': 17}), (7, 12, {'l': 1})]\n"
     ]
    }
   ],
   "source": [
    "def list2geosafe(G_list):\n",
    "    \n",
    "    nodes_state = []\n",
    "    edges_state = []\n",
    "    \n",
    "    for eps in G_list[0][0]:\n",
    "        nodes_state.append((eps[0], {'eps': True,  'r': False, 'W': eps[1], 'q': eps[6] if eps[6] is not None else math.inf, 'd': eps[3]}))\n",
    "        \n",
    "    for trans in G_list[0][1]:\n",
    "        nodes_state.append((trans[0], {'eps': False,  'r': False, 'W': 0, 'q': trans[1] if trans[1] is not None else math.inf, 'd': 0}))\n",
    "        \n",
    "    for r in G_list[0][2]:\n",
    "        nodes_state.append((r[0], {'eps': False,  'r': True, 'W': 0, 'q': r[1] if r[1] is not None else math.inf, 'd': 0}))\n",
    "        \n",
    "    for edge in G_list[1]:\n",
    "        edges_state.append((edge[2], edge[3], {'l' : edge[4]}))\n",
    "    \n",
    "    print(nodes_state)\n",
    "    print(edges_state)\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes_state)\n",
    "    G.add_edges_from(edges_state)\n",
    "    \n",
    "    return G\n",
    "        \n",
    "G = list2geosafe(G_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Partie 4 : 1ers Résultats  avec la contrainte cumulative\n",
    "\n",
    "### 4.1 Présentation\n",
    "Une majeure partie de notre projet a été de comprendre la modélisation a réaliser et de la réaliser de façon a respecter les contraintes imposées. Ce n'est que lors de la dernière séance que nous avons pu commencer à essayer notre modèle sur des données.  \n",
    "\n",
    "C'est pour celà que dans cette partie nous ne présenterons qu'un simple cas de résolution, sur un petit graphe réalisé à la main. Cette étape nous parraît être la première marche de la pyramide à gravir pour résoudre un problème d'évacuation  complexe.\n",
    "\n",
    "\n",
    "Le problème de la contrainte cumulative est qu'elle attend des constantes entières et non des variables dans l'interval pulse. \n",
    "Nous avons donc essayé de fixer ces valeurs :\n",
    "- D'abord en fixant S, le starting date, à 0 pour tout le monde. Cependant, d'après la contrainte cumulative elle-même, il faudrait aussi fixer la durée. Or, si on fixe la durée, on doit fixer le taux h (qui nous permet d'avoir la date de fin et donc la durée). Et si on fixe h en plus de fixer s, on a fixé toutes les variables que l'on cherche à définir. Donc on n'a plus de variable à déterminer ...\n",
    "```\n",
    "  siuv = s[v]+l[v,u]   \n",
    "  eiuv = e[v]+ l[v,u]   \n",
    "  phiarc += mdl.pulse((siuv, eiuv-siuv), h[v])\n",
    "            \n",
    "  mdl.add( phiarc <= q[u])\n",
    "```\n",
    "  \n",
    "avec e :\n",
    "```\n",
    "  e[v] == s[v] + W[v]/h[v]\n",
    "```\n",
    "\n",
    "- SOLUTION : On fixe le taux d'évacuation h. Ainsi, on a une durée fixe et on veut déterminer l'heure de départ s.\n",
    "\n",
    "### 4.2 Modèle adapté\n",
    "\n",
    "En utilisant la contrainte cumulative, on peut \"simplifier\" notre modèle qui était sans contrainte cumulative. \n",
    "D'autre part, pour essayer de résoudre un modèle simple, on fixe h, le taux d'évacuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.cp.model import CpoModel\n",
    "from docplex.cp.model import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG \n",
    "from config_duc import setup\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geosafe_model(l, q, eps, r, W, H, d,chemin):\n",
    "    '''       \n",
    "    Int  Matrix l: length path from i to j = G.l[i,j]. No path ij <--> G.l[i,j] = 0\n",
    "    Int  Array  q: capacity of node i <--> G.q[i]\n",
    "    Bool Array  eps: evacuation node \n",
    "    Bool Array  r: safe node\n",
    "    Int  Array  W: initial population at node i <--> W[i]\n",
    "    Int         H : Time span\n",
    "    Int  Array  d: deadline to leave the node\n",
    "    '''\n",
    "    \n",
    "    nb_node = q.shape[0] # ou len(q)\n",
    "    nodes = np.arange(nb_node) # id nodes, i.e [1,2,3,4, ...]\n",
    "    total_population = np.sum(W)\n",
    "    \n",
    "    t = !eps & !r # transition node\n",
    "\n",
    "    mdl = CpoModel(name='geosafe')\n",
    "    \n",
    "    # == Output ==\n",
    "    # starting date\n",
    "    #s = np.array([0,0,0,0,0,0])\n",
    "    #s = np.array( mdl.integer_var_list(nb_node, min=0, max = H, name=\"s\") ) # TODO : affiner max =H-w(v)/q(v)\n",
    "    \n",
    "    # == Fix h ==    \n",
    "    # h = np.array( mdl.integer_var_list(nb_node, min=0, max = 100, name=\"h\") ) # T0DO : affiner max =q[v]\n",
    "    # evacuation rate aka. height of package\n",
    "    h = np.array([5,5,5,5,5,5])\n",
    "    #h = np.array([1,1,1,1,1,1])\n",
    "    \n",
    "    # == Interval definition for cumulative constraint ==\n",
    "    itvs={}\n",
    "    for v in nodes[eps]:  \n",
    "        for u in chemin[v]: \n",
    "            duration = W[v]/h[v]\n",
    "            itvs[v,u]=mdl.interval_var(start=[int(l[v,u]), H], size= int(duration))\n",
    "\n",
    "\n",
    "    #  CUMULATIVE CONSTRAINT with a fixed h\n",
    "    for v in nodes[eps]: # pour chaque resource on associe une tâche \n",
    "        # que l'on duplique ensuite sur chaque arc critique\n",
    "        phiarc=step_at(0, 0)\n",
    "        for u in chemin[v]: \n",
    "            phiarc += mdl.pulse(itvs[v,u], h[v])       \n",
    "            mdl.add( phiarc <= q[u])\n",
    "    \n",
    "    \n",
    "    # ==Objective ==\n",
    "    mdl.add(\n",
    "        #because h is fixed :\n",
    "        #mdl.minimize(mdl.max(itvs[eps,] + W[eps]/h[eps] - d[eps])) \n",
    "         mdl.minimize(\n",
    "             mdl.max(\n",
    "                 mdl.end_of(\n",
    "                        itvs[v,(chemin[v][len(chemin[v])-2])])\n",
    "                 for v in nodes[eps] \n",
    "             )\n",
    "         )\n",
    "    )\n",
    "    \n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Définition d'un simple graphe pour tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "global_d = 100 # TODO: delete this one, just for debug\n",
    "\n",
    "# TODO: Maybe we should use eps = W > 0, so that do not need to use 'eps' attribute?\n",
    "nodes_state = [\n",
    "    (1, {'eps': True,  'r': False, 'W': 5, 'd': global_d}),\n",
    "    (2, {'eps': True,  'r': False, 'W': 5, 'd': global_d}),\n",
    "    (3, {'eps': True,  'r': False, 'W': 5, 'd': global_d}),\n",
    "    (4, {'eps': False, 'r': False, 'W': 0, 'd': global_d}),\n",
    "    (5, {'eps': False, 'r': False, 'W': 0, 'd': global_d}),\n",
    "    (6, {'eps': False, 'r': True,  'W': 0, 'd': global_d})\n",
    "]\n",
    "\n",
    "edges_state = [\n",
    "    (1, 4, {'l' : 4}),\n",
    "    (2, 4, {'l' : 3}),\n",
    "    (4, 5, {'l' : 7}),\n",
    "    (3, 5, {'l' : 3}),\n",
    "    (5, 6, {'l' : 10})\n",
    "]\n",
    "chemin = [\n",
    "    [0,3,4,5],\n",
    "    [1,3,4,5],\n",
    "    [4,5]\n",
    "]\n",
    "\n",
    "G.add_nodes_from(nodes_state)\n",
    "G.add_edges_from(edges_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _node_attribute_(G, attribute='eps'):\n",
    "    '''\n",
    "    Author: Duc Hau :D\n",
    "    Return a numpy boolean array of attribute\n",
    "    '''\n",
    "    values_tmp = nx.get_node_attributes(G, attribute).values()\n",
    "    return np.array(list(values_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(_node_attribute_(G, attribute='W'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path length\n",
    "l = nx.floyd_warshall_numpy(G, weight='l')\n",
    "\n",
    "# Node capacities (shouldn't it be the path??)\n",
    "q = np.array([20,20,20,20,20,20])\n",
    "\n",
    "# If the node is in EPSILON (evacuating node)\n",
    "eps = _node_attribute_(G, 'eps')\n",
    "\n",
    "# If the node is in the ROOT (safe node)\n",
    "r = _node_attribute_(G, 'r')\n",
    "\n",
    "# Initial population\n",
    "W = _node_attribute_(G, 'W')\n",
    "\n",
    "# Time span\n",
    "H = 200\n",
    "\n",
    "# Deadline for evacutation\n",
    "d = _node_attribute_(G, 'd')\n",
    "\n",
    "# Solver configuration\n",
    "ctx = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes  [0 1 2]\n",
      "l : \n",
      "  [[ 0. inf inf  4. 11. 21.]\n",
      " [inf  0. inf  3. 10. 20.]\n",
      " [inf inf  0. inf  3. 13.]\n",
      " [inf inf inf  0.  7. 17.]\n",
      " [inf inf inf inf  0. 10.]\n",
      " [inf inf inf inf inf  0.]]\n",
      "i ,  0\n",
      "chemin  [0, 3, 4, 5]\n",
      "0.0\n",
      "4.0\n",
      "11.0\n",
      "21.0\n",
      "i ,  1\n",
      "chemin  [1, 3, 4, 5]\n",
      "0.0\n",
      "3.0\n",
      "10.0\n",
      "20.0\n",
      "i ,  2\n",
      "chemin  [4, 5]\n",
      "3.0\n",
      "13.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_node = q.shape[0] # ou len(q)\n",
    "nodes = np.arange(nb_node) # id nodes, i.e [1,2,3,4, ...]\n",
    "print(\"nodes \",nodes[eps])\n",
    "print(\"l : \\n \",l)\n",
    "\n",
    "\n",
    "for i in nodes[eps]:\n",
    "    print(\"i , \",i)\n",
    "    print(\"chemin \", chemin[i])\n",
    "    for j in chemin[i] :\n",
    "        print(l[i,j])\n",
    "        \n",
    "        \n",
    "chemin[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = geosafe_model(l, q, eps, r, W, H, d, chemin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Solve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-db757ac7ab52>:45(stream:19:11): Warning: Cumulative expression 'stepAt': height is zero, expression is zero everywhere.\n",
      "                                                             stepAt(0, 0)\n",
      "<ipython-input-41-db757ac7ab52>:45(stream:26:11): Warning: Cumulative expression 'stepAt': height is zero, expression is zero everywhere.\n",
      "                                                             stepAt(0, 0)\n",
      "<ipython-input-41-db757ac7ab52>:45(stream:33:11): Warning: Cumulative expression 'stepAt': height is zero, expression is zero everywhere.\n",
      "                                                             stepAt(0, 0)\n",
      " ! ----------------------------------------------------------------------------\n",
      " ! Minimization problem - 10 variables, 10 constraints\n",
      " ! Initial process time : 0.00s (0.00s extraction + 0.00s propagation)\n",
      " !  . Log search space  : 33.2 (before), 33.2 (after)\n",
      " !  . Memory usage      : 549.5 kB (before), 549.5 kB (after)\n",
      " ! Using parallel search with 4 workers.\n",
      " ! ----------------------------------------------------------------------------\n",
      " !          Best Branches  Non-fixed    W       Branch decision\n",
      "                        0         10                 -\n",
      " + New bound is 12\n",
      " *            12       10  0.00s        1      (gap is 0%)\n",
      " ! ----------------------------------------------------------------------------\n",
      " ! Search completed, 1 solution found.\n",
      " ! Best objective         : 12 (optimal - effective tol. is 0)\n",
      " ! Best bound             : 12\n",
      " ! Number of branches     : 12\n",
      " ! Number of fails        : 12\n",
      " ! Total memory usage     : 1.3 MB (1.2 MB CP Optimizer + 0.0 MB Concert)\n",
      " ! Time spent in solve    : 0.00s (0.00s engine + 0.00s extraction)\n",
      " ! Search speed (br. / s) : 1200.0\n",
      " ! ----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      " Result:\n",
      "-------------------------------------------------------------------------------\n",
      "Model constraints: 10, variables: integer: 0, interval: 10, sequence: 0\n",
      "Solve status: Optimal\n",
      "Search status: SearchCompleted, stop cause: SearchHasNotBeenStopped\n",
      "Solve time: 0.01 sec\n",
      "-------------------------------------------------------------------------------\n",
      "Objective values: (12,)\n",
      "          bounds: (12,)\n",
      "          gaps: (0.0,)\n",
      "_ITV_41: (start=0, end=1, size=1, length=1)\n",
      "_ITV_42: (start=4, end=5, size=1, length=1)\n",
      "_ITV_43: (start=11, end=12, size=1, length=1)\n",
      "_ITV_44: (start=21, end=22, size=1, length=1)\n",
      "_ITV_45: (start=0, end=1, size=1, length=1)\n",
      "_ITV_46: (start=3, end=4, size=1, length=1)\n",
      "_ITV_47: (start=10, end=11, size=1, length=1)\n",
      "_ITV_48: (start=20, end=21, size=1, length=1)\n",
      "_ITV_49: (start=3, end=4, size=1, length=1)\n",
      "_ITV_50: (start=13, end=14, size=1, length=1)\n"
     ]
    }
   ],
   "source": [
    "mdl.solve()\n",
    "sol = mdl.solve(Presolve='On', Workers='Auto')\n",
    "print(sol.get_solver_log())\n",
    "\n",
    "print('\\n\\n Result:')\n",
    "if sol.is_solution():\n",
    "    sol.print_solution()\n",
    "else:\n",
    "    print('Problem does not have solution')\n",
    "    sol.print_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution pour h non contraignant** :  \n",
    "\n",
    "On voit ici qu'en fixant h de façon non contraignante, on retrouve les données attendues que nous avons crées. C'est en quelque sorte un model checker.\n",
    "\n",
    "```\n",
    "! ----------------------------------------------------------------------------\n",
    " ! Minimization problem - 10 variables, 10 constraints\n",
    " ! Initial process time : 0.00s (0.00s extraction + 0.00s propagation)\n",
    " !  . Log search space  : 33.2 (before), 33.2 (after)\n",
    " !  . Memory usage      : 549.5 kB (before), 549.5 kB (after)\n",
    " ! Using parallel search with 4 workers.\n",
    " ! ----------------------------------------------------------------------------\n",
    " !          Best Branches  Non-fixed    W       Branch decision\n",
    "                        0         10                 -\n",
    " + New bound is 12\n",
    " *            12       10  0.00s        1      (gap is 0%)\n",
    " ! ----------------------------------------------------------------------------\n",
    " ! Search completed, 1 solution found.\n",
    " ! Best objective         : 12 (optimal - effective tol. is 0)\n",
    " ! Best bound             : 12\n",
    " ! Number of branches     : 12\n",
    " ! Number of fails        : 12\n",
    " ! Total memory usage     : 1.3 MB (1.2 MB CP Optimizer + 0.0 MB Concert)\n",
    " ! Time spent in solve    : 0.00s (0.00s engine + 0.00s extraction)\n",
    " ! Search speed (br. / s) : 1200.0\n",
    " ! ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    " Result:\n",
    "-------------------------------------------------------------------------------\n",
    "Model constraints: 10, variables: integer: 0, interval: 10, sequence: 0\n",
    "Solve status: Optimal\n",
    "Search status: SearchCompleted, stop cause: SearchHasNotBeenStopped\n",
    "Solve time: 0.01 sec\n",
    "-------------------------------------------------------------------------------\n",
    "Objective values: (12,)\n",
    "          bounds: (12,)\n",
    "          gaps: (0.0,)\n",
    "_ITV_41: (start=0, end=1, size=1, length=1)\n",
    "_ITV_42: (start=4, end=5, size=1, length=1)\n",
    "_ITV_43: (start=11, end=12, size=1, length=1)\n",
    "_ITV_44: (start=21, end=22, size=1, length=1)\n",
    "_ITV_45: (start=0, end=1, size=1, length=1)\n",
    "_ITV_46: (start=3, end=4, size=1, length=1)\n",
    "_ITV_47: (start=10, end=11, size=1, length=1)\n",
    "_ITV_48: (start=20, end=21, size=1, length=1)\n",
    "_ITV_49: (start=3, end=4, size=1, length=1)\n",
    "_ITV_50: (start=13, end=14, size=1, length=1)\n",
    "```\n",
    "\n",
    "**Solution pour h contraignant** :  \n",
    "\n",
    "Ici on fixe h à 1 et non plus à 5. On voit que l'on a une solution les intervals qui ont changés. De même, la borne n'est plus la même.\n",
    "\n",
    "```\n",
    "! ----------------------------------------------------------------------------\n",
    " ! Minimization problem - 10 variables, 10 constraints\n",
    " ! Initial process time : 0.00s (0.00s extraction + 0.00s propagation)\n",
    " !  . Log search space  : 33.2 (before), 33.2 (after)\n",
    " !  . Memory usage      : 549.5 kB (before), 549.5 kB (after)\n",
    " ! Using parallel search with 4 workers.\n",
    " ! ----------------------------------------------------------------------------\n",
    " !          Best Branches  Non-fixed    W       Branch decision\n",
    "                        0         10                 -\n",
    " + New bound is 16\n",
    " *            16       10  0.00s        1      (gap is 0%)\n",
    " ! ----------------------------------------------------------------------------\n",
    " ! Search completed, 1 solution found.\n",
    " ! Best objective         : 16 (optimal - effective tol. is 0)\n",
    " ! Best bound             : 16\n",
    " ! Number of branches     : 12\n",
    " ! Number of fails        : 12\n",
    " ! Total memory usage     : 1.3 MB (1.2 MB CP Optimizer + 0.0 MB Concert)\n",
    " ! Time spent in solve    : 0.00s (0.00s engine + 0.00s extraction)\n",
    " ! Search speed (br. / s) : 1200.0\n",
    " ! ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    " Result:\n",
    "-------------------------------------------------------------------------------\n",
    "Model constraints: 10, variables: integer: 0, interval: 10, sequence: 0\n",
    "Solve status: Optimal\n",
    "Search status: SearchCompleted, stop cause: SearchHasNotBeenStopped\n",
    "Solve time: 0.01 sec\n",
    "-------------------------------------------------------------------------------\n",
    "Objective values: (16,)\n",
    "          bounds: (16,)\n",
    "          gaps: (0.0,)\n",
    "_ITV_31: (start=0, end=5, size=5, length=5)\n",
    "_ITV_32: (start=4, end=9, size=5, length=5)\n",
    "_ITV_33: (start=11, end=16, size=5, length=5)\n",
    "_ITV_34: (start=21, end=26, size=5, length=5)\n",
    "_ITV_35: (start=0, end=5, size=5, length=5)\n",
    "_ITV_36: (start=3, end=8, size=5, length=5)\n",
    "_ITV_37: (start=10, end=15, size=5, length=5)\n",
    "_ITV_38: (start=20, end=25, size=5, length=5)\n",
    "_ITV_39: (start=3, end=8, size=5, length=5)\n",
    "_ITV_40: (start=13, end=18, size=5, length=5)\n",
    "```\n",
    "\n",
    "## Partie 5 : Conclusion\n",
    "\n",
    "L'équipe ADA a trouvé très interressant de travailler sur ce projet très concrêt, quoique difficile. Nous avons réussi à modéliser le problème en comprenant chaque choix éffectués par l'équipe GeoSafe. Notre modélisation avec la contrainte cumulative est maintenant prêt à être utilisé avec les données issues du générator. Il aurait été interressant de pouvoir continuer ce projet et d'arriver à trouver les résultats de GeoSafe.\n",
    "\n",
    "L'équipe suggère pourquoi pas d'organiser une rencontre avc l'un des membre de GeoSafe si ce projet vient à se réitérer l'année prochaine. En effet, ADA aurait eu des questions à poser directement aux concepteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
