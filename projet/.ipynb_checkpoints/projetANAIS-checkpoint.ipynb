{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import setup\n",
    "setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Projet AP : Late Evacuation Planning Problem\n",
    " \n",
    "Team : ADA\n",
    " \n",
    "Team members :\n",
    "- Anaïs Rabary  \n",
    "- Duc Hau Nguyen  \n",
    "- Adrien Mega  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 :  Introduction projet GEO-SAFE\n",
    "TODO : A reformuler pour l'intro  \n",
    "Présentation d'après l'artique A study of Evacuation Planning for Wildfires de Christian Artigues, Emmanuel Hebread, Yanninck Pencole, Andreas Schutt et Peter Stuckey. (dans le dossier /docs du git)\n",
    "\n",
    "Le but de ce projet est de pouvoir **assister la prise de décision des autorités lors de l'évacuation à grande échelle (de la population) pendant un feu de forêts**. Pour cela, il faut modéliser le problème pour vérifier ensuite que  l'évacuation de la population pendant un feu est bien réalisable. \n",
    "Pour cela, on utilise des outils d'optimisation.\n",
    "\n",
    "La population se trouve sur des noeuds à évacuer. Dans la \"vraie vie\", il y a 3 catégories de personnes à évacuer : les personnes qui partent tôt, celles qui se réfugie dans un lieu et celles qui restent \"se battre\". Les derniers sont les personnes qui concernent l'objet de la modélisation, ce sont des personnes qui partent tard.\n",
    "\n",
    "Dans le cas de modélisation d'evacuation lors d'innondation, les méthodes utilisées étaient malléables pour représenter l'évacuation de la population. Il y avait des contraintes cumulatives par segments de route. \n",
    "La propagation des feu est beaucoup moins prédictible que celle des innondations. En effet, cela n'est pas fixe selon la topologie, mais dépend plus de la présence de combustible et de la vitesse et direction du vent. Donc la méthode d'évacutaion doit être plus robuste pour pouvoir prédire différents scénarios. \n",
    "\n",
    "Il faut éviter le risque de congestion et donc, pour cela, on peut **retarder le départ de la population**. Il est aussi possible **d'influer sur le taux d'évacuation** (moduler la méthode pour déclancher l'alarme).\n",
    "\n",
    "En plus de minimiser le temps d'évaciation de la population, le but est de maximiser le minimum \"safety margin\" spatial et temporel pondéré par la population, sur chaque segment de route. Il faut donc être le plus loin et le plus rapidement possible du feu.\n",
    "\n",
    "L'équipe GeoSafe a introduit une heuristique et un propagateur de contraintes de fluw global.\n",
    "\n",
    "\n",
    "## Partie 2 : Evacuation Planning Problem\n",
    "Notre équipe (Duc, Adrian et Anaïs) a choisi de modéliser le problème de façon à le résoudre en **programmation par contraintes** avec CP Optimizer.\n",
    "\n",
    "Il faut que l'on trouve la date à laquelle on commence l'évacuation pour chaque noeud, ainsi que le taux d'évacuation. Le taux d'évacuation est en fait une modélisation du niveau de ressources utilisées par les autorités pour évacuer les gens.  \n",
    "\n",
    "### 2.1 Hypothèses\n",
    "Quelques hypothèses posées par l'équipe GeoSafe :\n",
    "- Les authorités ont déjà identifié des routes accessibles et des points de refuges en sécurité. Chaque sommet à évacuer a donc une seule route d'évacuation. Il y a 1 seul et même point de refuge à atteindre par toute la population a évacuer. Il se peut qu'il y ait une congestion sur un des segment de route partagé par plusieurs points.\n",
    "- Les autorités ont déja estimé le nombre d'habitant à évacuer (la population de ceux qui partent tard)\n",
    "- la modélisation du feu donne une deadline pour chaque segment (date à laquelle le feu arrive).\n",
    "- Une fois que l'évacuation d'un point a commencé, le process ne peut pas être interrompu. Les personnes en cours d'évacuation ne s'arrêtent jamais\n",
    "- C'est non-préemptif.\n",
    "- le flux d'évacuation reste constant durant tout le processus d'évacuation.\n",
    "\n",
    "### 2.2 Modélisation \n",
    "Un argre $G= (\\varepsilon \\cup T \\cup \\{r\\}, A)$ qui représente les routes depuis les sommets à évacuer $\\varepsilon$ vers le refuge $r$ en passant par des noeuds de transit $T$\n",
    "\n",
    "- sur chaque noeud $v\\in\\varepsilon$, il y a $W_{v}$ personnes à évacuer. Cela correspond à **population_i** du .evac.\n",
    "- Chaque arc alant de $u$ à $u'$, de longueur $l_{uu'}$ a une capacité $q_{u}$. Cela corespond à **capacity_y** du .evac.\n",
    "- $H=[0,h]$ représente l'interval de temps pour l'évacuation.\n",
    "Il faut associer chaque $v$ à un réel $s_{v}$ représentant le **retard du préavis d'évacuation** ainsi qu'a une courbe de réponse $\\phi_{v}$ décrivant le **flow d'évacuation** d'un noeud $v$ a un taux $\\phi_{v}(t)$. avant $s_{v}$ le taux $\\phi_{v}$ est à 0.\n",
    "$$\\int_{0}^{H}\\phi_{v}(t)dt=w_{v} $$\n",
    "Le flow $\\phi_u$ pour n'importe quel arc $u-v$ à n'importe quel moment noeud : \n",
    "$$\\phi_u(t)=\\sum_{v\\in descendants(u)} \\phi_{v}(t-l_{uv}-s_{v})$$  \n",
    "\n",
    "On peut aussi le réécrire :\n",
    "$$\\phi_u(t)=\\sum_{V\\in descendants(u),\\: s_v+l_{uv}\\le t \\lt s_v+l_{uv}+\\frac{w_v}{h_v}} h_v$$  \n",
    "\n",
    "Ici, $\\phi_v$ est une courbe de réponse simple. Le flux sortant $\\phi_v$ est une variable de décision continue et qui reste constante penant le process d'évacuation.\n",
    "On note aussi :\n",
    "$$ \\phi_v = h_v\\: during\\: [s_v,e_v]\\: with\\: e_v=s_v + \\frac{w_v}{h_v}$$\n",
    "\n",
    "\n",
    "- Il y a une tache pour chaque noeud à évacuer. Pour chaque tâche, on a un **taux constant d'évacuation** $\\phi_v \\le q_{v}$ et une **heure de début d'évacuation** $s_{v}\\in [0, H-\\frac{w_v}{h_v}]$\n",
    "\n",
    "**CONTRAINTES** :   \n",
    "Il n'y a qu'un seul type de contraintes pour éviter les bouchons (donc éviter d'avoir un flux plus grand que la capacité d'un arc) : $\\phi_v \\le q_{v}$\n",
    "\n",
    "**OBJECTIF** :  \n",
    "Chaque noeud de transit a une date au plus tard (due date) $d_u$, date à partir de laquelle la route n'est plus en sécurité (à cause du feu). L'objectif est donc de minimiser l'écart de temps maximal entre lequel la population quitte $u$ et la due date $d_u$.\n",
    "$$\\min \\max_{u\\in T,v\\in descendants(u)} s_v + \\frac{h_v}{w_w} + l_{uv} - d_u$$\n",
    "\n",
    "Cette fonction objectif se simplifie en \n",
    "$$\\min \\max_{v\\in\\varepsilon} s_v + \\frac{h_v}{w_w} - d_v$$\n",
    "avec $d_v=\\min_{u\\in T}\\{d_u-l_{uv}\\}$\n",
    "\n",
    "**OBSERVATION**:   \n",
    "Pour chaque noeud de transit $u$ et $u'$, avec $u'$ déscendant de $u$ un bouchon sur $u'$ entraine un bouchon sur $u$. Donc, il ne faut checker l'occurance de bouchons uniquement si la capacité de $u$ est supérieur à la capacité de sons ascendant $v$ ( $\\forall v \\in p'(u),q_u \\gt q_v$ )  \n",
    "\n",
    "**SIMPLIFICATION**:     \n",
    "Sur un chemin de $u$ vers $u'$ sans branches, on garde la capacité de l'arc minimum. \n",
    "Par exemple, avec c'<c, on garde donc la capacité c' :  \n",
    "            S5  `  \n",
    "```\n",
    "S1 ___ S2 ___ S3 ___ S4  \n",
    "     c     c'  |    \n",
    "               S5  \n",
    "```\n",
    "   \n",
    "```\n",
    "S1 ___ S2 ___ S3 ___ S4  \n",
    "     c'     c'  |    \n",
    "               S5  \n",
    "```\n",
    "\n",
    "\n",
    "### 2.3 Utilisation des contraintes cumulatives\n",
    "L'approche de base se fait avec des contraintes cumulatives simples.  \n",
    "**NOTATION** :   \n",
    "Pour une variable $x$, $\\bar{x}$ signifie la plus grande valeur de x et $\\underline{x}$, la plus petite valeur de x. \n",
    "\n",
    "Si on prend une selection de **tâches** $J$ avec une **heure de départ** $s_{i} \\in [\\underline{s_i}, \\bar{s_i}]$, avec une **durée de process** $p_i \\in [\\underline{p_i},\\bar{p_i}]$, une **hauteur** $h_i \\in [\\underline{h_i}, \\bar{h_i}]$ et une **resource** $r$ avec une **capacité constante** $q_r$, on défini la contrainte cumulative comme :\n",
    "$$ \\sum_{i\\in J|s_i\\le t\\le s_i+p_i} h_i \\le q_r, \\forall t\\in H$$\n",
    "\n",
    "Donc pour modéliser le problème, il suffit d'associer une tâche $v$ à chaque noeud à évacuer ($v \\in \\varepsilon$), avec une hauteur $h_v \\in ]0, q_v]$, avec une heure de départ $ s_v \\in [0, H-\\frac{w_v}{q_v}]$, une heure de \"completion\" $e_v \\in [\\frac{w_v}{q_v}, H]$. Puis il faut dupliquer et transformer cette tâche pour chaque arc critique de transit jusqu'au point de refuge. On note $i_{uv}$ la duplication du noeud $v$ sur l'arc critique $u$.\n",
    "\n",
    "On a donc :\n",
    "$$cumulative((s_{i_{uv}}, e_{i_{uv}} - s_{i_{uv}}, h_{i_{uv}})_{v\\in L(u)}, q_u) \\forall u \\in T $$\n",
    "$$w_v=h_v(e_v-s_v) \\forall v \\in \\varepsilon$$\n",
    "$$s_{i_{uv}} = s_v +l_{uv} \\forall u\\in T, \\forall v \\in L(u)$$\n",
    "$$e_{i_{uv}} = e_v +l_{uv} \\forall u\\in T, \\forall v \\in L(u)$$\n",
    "$$h_{i_{uv}} = h_v \\forall u\\in T, \\forall v \\in L(u)$$\n",
    "\n",
    "Le problème avec les contraintes cumulatives \"classiques\" c'est qu'elles ne considères que les bornes inférieurs des domaines de solutions possibles. (*cf.exemple p7 de l'article*). Elles ne permettent pas de raisonner avec l'énergie totale de chaque tâche.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 La contrainte cumulative énergétique\n",
    "Le but de cette nouvelle contrainte est solliciter le fait que le produit $(durée * taux)$ soit constant. Pour cela il faut une contrainte un peu plus globale. \n",
    "La contrainte **energetic_cumulative**($(s_i,e_i,h_i,w_v)_{i\\in J}, q_r$) se traduit comme :\n",
    "$$ \\sum_{i\\in J |s_i\\le t\\le e_i} h_i \\le q_r \\forall t\\in H$$\n",
    "$$w_i=h_i(e_i-s_i) \\forall i \\in J$$\n",
    "Cette contrainte est NP-complet puisque le cas particulier où la hauteur $h_i$ est fixée est une contrainte cumulative.\n",
    "Cependant, comme les tâches sont malléables, le problème devient plus simple sous certaines hypothèses. \n",
    "\n",
    "En particulier :\n",
    "- on considère que l'on n'a pas les valeurs minimum des hauteurs $h_i$ des tâches i, que l'on note **energetic_cumulative** \\ $\\{ h-\\}$.\n",
    "\n",
    "On peut donc définir 3 relaxations :\n",
    "- \"$r$\" représente la release date pour laquelle la relaxation signifie que $s_i-=0$ pour chaque tache $i\\in J$\n",
    "- \"$d$\" représente la date butoire pour laquelle la relaxation implique $e_i+=H$ pour chaque tâche $i\\in J$\n",
    "- \"$h+$\" qui représente la hauteur maximale por laquelle la relaxation implique $h_i+=q_r$ pour chaque tâche $i \\in J$\n",
    "\n",
    "On peut modéliser la contrainte cumulative énergétique pour slaquelle les contraintes $S \\in \\{h-, h+, r,d\\}$ sont relaxée.\n",
    "\n",
    "**THEOREME 1** **energetic_cumulative**  $\\{h-,x,y\\}\\: is\\: in\\: P\\: for\\: any\\: x \\ne y \\in \\{r,d,\\bar{h}\\}\\: scénarios$\n",
    "\n",
    "L'algorithme 1 permet de plannifier des tâches qui commencent à 0 et qui finnissent au plus tard à $h_i \\le h_i+$. La contrainte est donc satisfaisable si et seulement si l'heure de completion la plus tard est inférieure à H. \n",
    "\n",
    "**THEOREM 2** **Energetic_cumulative** $\\{h-,x,y\\}\\: is\\: NP-Complete\\: for\\: any\\: x \\in \\{r,d,\\bar{h}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Contraintes de Flow Global\n",
    " Si on veut avoir un taux d'activité qui varie avec le temps, on peut utiliser un propagateur de flux adapté à la contrainte **energetic-cumulative**.\n",
    " Ce propagateur fonctionne comme ci-après :\n",
    " - Construit un réseau de flow relaxé, appelé $f(D)$ \n",
    " - propage en utilisant le domaine courrant $D$.\n",
    " \n",
    "**THEOREM 3** $any \\: solution \\: to$ **Energetic_cumulative** $\\: given\\: a\\: current\\: domain \\: D,\\: is\\: extensible\\: to\\: a\\: solution\\: of\\: the\\: flow\\: network\\: f(D)$\n",
    " \n",
    " Pour plus d'info, regarder la partie 5 de l'article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Heuristique pour la borne supérieur\n",
    "Heuristique de compression pour trouver une borne supérieur initiale.  \n",
    "On suppose que le domaine du taux initial d'évacuation est $D(h_v)=[1,q_v]$ pour chaque noeud d'évacuation.\n",
    "On suppose aussi que la planification des tâches d'évacuation commençantt à $t=0$ avec le taux minimum d'évacuation permet de trouver une solution fesable, avec un coût élevé. \n",
    "\n",
    "Commençant avec cette soution, $(\\forall v \\in \\varepsilon, s_v :=0, e_v=w_v, h_v:=1)$, les heures de départ minimales et maximales sont construite pour chaque noeud de transit. De même pour interval correspondant pour la contrainte de flow global.\n",
    "\n",
    "A partir de cette solution, un process iteratif est lancé. A chaque itération, la tâche critique est identifiée. Puis, sa durée est diminuée et sa largeur est augmentée en conséquence jusqu'à ce qu'on ne puisse plus augmenté/diminuer la largeur/durée sans dépasser la capacité de l'arc ou que la tâce ne devienne plus critiqeu et qu'une autre tâche le devienne.  Dans le cas où une nouvelle tâche devient critique, le process itératif se relance sur ce nouvel arc.   \n",
    "\n",
    "L'heuristique peret de donner une solution initiale au solver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code de la MODELISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 :  Generator \n",
    "Generator est une instance qui permet de générer aléatoirement un réseau de routes et de propager un simple model de feu. Les données générées prennent en compte des propagations de contraintes qu'il convient d'expliquer et de comprendre !\n",
    " \n",
    "### 3.1 Install module\n",
    " Pour générer les données utilisées après par le projet, il faut utiliser le générateur du projet evacsim présent sur le git https://github.com/ehebrard/evacsim\n",
    " Il faut l'utiliser avec python 2 et avoir installé decorator et networkx.\n",
    " Note : il faut un dossier data dans le projet. C'est dans ce dossier que seront déposées les données générées.  \n",
    " \n",
    " ***\n",
    " \n",
    " Commande pour installer :  \n",
    " `python setup.py install --user`\n",
    " \n",
    " Les commandes pour générer :  \n",
    " `python generator.py --road test --printroad`  \n",
    " `python generator.py test --evacuation --printfire --seed 10`\n",
    " \n",
    " NOTE : avec la commande : `python generator.py --road test --evacuation --printfire --seed 10 --printevac`on peut voir la route d'évacuation  \n",
    " \n",
    " ***  \n",
    " \n",
    " Pour générer une nouvelle instance de feu, il suffit de changer le paramètre seed.\n",
    " \n",
    " ### 3.2 Modélisation données générées\n",
    " FORMAT :\n",
    " n m population_1 maximum_rate_1 duedate_1 ... population_n maximumrate_n duedate_n capacity_1 k_1 i_1_1 offset_i_1_1 ... i_k_1 offset_i_k_1 ... capacity_m k_m i_1_m offset_i_1_m ... i_k_m offset_i_k_m\n",
    " \n",
    "- **n** is the number of evacuation nodes\n",
    "- **m** is the number of relevant transit arcs \n",
    "- **Population_i** : population du noeud i a évacuer.\n",
    "- **Maximum_rate_i** : taux max de personnes pouvant être évacuées en même temps\n",
    "- **duedate_i** : Date à laquelle le noeud doit être évacué\n",
    "- **capacity_y** is the capacity of transit arc y\n",
    "- **k_y** is the number of population groups transiting by this arc\n",
    "- **offset_i_x_y** is the date at which population group i_x_y reaches this arc if starting at time 0\n",
    "\n",
    "EXEMPLE :   \n",
    "- l1 : `10 8`  \n",
    "10 zones à évacuer avec 8 arcs à utiliser pour évacuer les zones  \n",
    "- l2 : `1677 70 66`   \n",
    "sur le sommet 1, 1677 personnes à évacuer, par pacquets de 70, avant la date 66  \n",
    "- l3 : `4161 70 40`  \n",
    "- l4 : `3817 70 36`  \n",
    "- l5 : `3745 70 92`  \n",
    "- l6 : `1379 72 126`   \n",
    "- l7 : `3359 71 115`  \n",
    "- l8 : `893 72 120`  \n",
    "- l9 : `463 72 54`  \n",
    "- l10: `4368 212 86`  \n",
    "- l11: `4987 70 44`  \n",
    "Sommet 10  \n",
    "- l12: `74 2 3 20 6 8`  \n",
    "Arc 1, capacité de 74 personnes, Nombre de Groupes transitant par cet arc(2), puis lire par tuple de 2 (3,20) : 3, num du groupe concerné, 20, date au plus tôt à laquelle la population peut partir si il part à t=0. Cela veut donc dire que si le groupe 3 part a t=4, il pourra traverser l'arc 1 à partir de t=24.(6,8).  \n",
    "- l13: `74 4 2 1 5 2 7 4 9 2`  \n",
    "arc2, capacité74 personnes, 4 groupes possibles puis (2,1), (5,2), (7,4), (9,2)  \n",
    "- l13: `206 8 0 13 1 15 2 16 4 14 5 17 7 19 8 9 9 17`  \n",
    "- l14: `72 2 0 2 1 4`  \n",
    "- l15: `203 10 0 33 1 35 2 36 3 40 4 34 5 37 6 28 7 39 8 29 9 37`  \n",
    "- l16: `72 5 2 4 4 2 5 5 7 7 9 5`  \n",
    "- l17: `72 2 7 3 9 1`  \n",
    "- l18: `138 7 0 8 1 10 2 11 4 9 5 12 7 14 9 12`  \n",
    "Arc 8 capacité de 138 personnes, ...    \n",
    "\n",
    "\n",
    "**NOTE IMPORTANTE ** : les couleurs des arcs correspondes à la capacité de la route. TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Récupération des données générées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import networkx as nx\n",
    "from docplex.cp.model import CpoModel\n",
    "from docplex.cp.model import *\n",
    "\n",
    "# Comme on ne peut pas définir la longueur d'un arc à partir des fichiers générés ...\n",
    "VALEUR_ARBITRAIRE_ARC_SORTIE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une première fonction parse le fichier graphe écrit par le générateur pour en récupérer le contenu.\n",
    "Ces données sont simplement retournées sous forme de listes (une pour les zones, une pour les arcs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4455, 70, 68]\n",
      "[509, 70, 22]\n",
      "[4584, 71, 128]\n",
      "[2902, 71, 122]\n",
      "[2808, 71, 84]\n",
      "[2744, 70, 22]\n",
      "[3982, 3982, 50]\n",
      "[1471, 70, 122]\n",
      "[1783, 71, 22]\n",
      "[358, 70, 68]\n",
      "[71, [[1, 0], [8, 0]]]\n",
      "[224, [[2, 17], [4, 35], [5, 30]]]\n",
      "[70, [[1, 3], [6, 3], [8, 3]]]\n",
      "[132, [[4, 29], [5, 24]]]\n",
      "[132, [[0, 0], [3, 8], [9, 0]]]\n",
      "[249, [[0, 18], [1, 23], [2, 30], [3, 26], [4, 48], [5, 43], [6, 23], [8, 23], [9, 18]]]\n",
      "[132, [[3, 8], [9, 0]]]\n",
      "[146, [[0, 1], [1, 6], [3, 9], [6, 6], [8, 6], [9, 1]]]\n"
     ]
    }
   ],
   "source": [
    "def read_evac(filename):\n",
    "    \n",
    "    with open(filename,\"r\") as file:\n",
    "        content = file.readlines()\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        \n",
    "        nbzones, nbarcs = content[0].split(\" \")\n",
    "        content.remove(content[0])\n",
    "    \n",
    "        lineszones = content[0:int(nbzones)]\n",
    "        linesarcs  = content[int(nbzones):int(nbzones)+int(nbarcs)]\n",
    "        \n",
    "        E = []\n",
    "        \n",
    "        for line in lineszones:\n",
    "            personnes, paquets, datemax = line.split(\" \")\n",
    "            E.append([int(personnes),int(paquets),int(datemax)])\n",
    "            \n",
    "        A = []\n",
    "        \n",
    "        for line in linesarcs:\n",
    "            \n",
    "            content = line.split(\" \")\n",
    "            capacite = content[0]\n",
    "            content = content[2:]\n",
    "            \n",
    "            groups = []\n",
    "            \n",
    "            for i in range(0,len(content),2):\n",
    "                numgroupe = content[i]\n",
    "                datemax = content[i+1]\n",
    "                \n",
    "                groups.append([int(numgroupe),int(datemax)])\n",
    "                \n",
    "            A.append([int(capacite),groups])\n",
    "            \n",
    "        return E,A\n",
    "        \n",
    "        \n",
    "# import os\n",
    "# os.listdir()\n",
    "\n",
    "E,A = read_evac(\"evacsim-master/data/test_10_25_2_10.evac\")\n",
    "\n",
    "print(*E, sep = \"\\n\")\n",
    "print(*A, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une lecture et un réarrangement sont ensuite appliqués afin de déduire et regrouper les données qui seront utiles à notre modèle de résolution. Ces données sont restituées sous la forme d'une liste plus complexe.\n",
    "\n",
    "Après avoir lu les propriétés de chaque sommet à évacuer, les arcs sont parcourus et ajoutés à la liste des arcs d'un sommet à évacuer. Les arcs sont ajoutés dans l'ordre de parcours.\n",
    "\n",
    "La dernière étape de cette fonction consiste à identifier les sommets intermédiaires entre les arcs, ainsi que le(s) sommet(s) de sûreté. Cette étape nous permet d'obtenir plusieurs propriétés des arcs que nous n'avions pas jusque là, comme le sommet d'origine / d'arrivée ou le temps de parcours d'un arc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " [\n",
      "  [\n",
      "   [\n",
      "    0,\n",
      "    4455,\n",
      "    70,\n",
      "    68,\n",
      "    64,\n",
      "    [\n",
      "     [\n",
      "      4,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      1\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      18\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ],\n",
      "   [\n",
      "    1,\n",
      "    509,\n",
      "    70,\n",
      "    22,\n",
      "    8,\n",
      "    [\n",
      "     [\n",
      "      0,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      2,\n",
      "      3\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      6\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      23\n",
      "     ]\n",
      "    ],\n",
      "    71\n",
      "   ],\n",
      "   [\n",
      "    2,\n",
      "    4584,\n",
      "    71,\n",
      "    128,\n",
      "    65,\n",
      "    [\n",
      "     [\n",
      "      1,\n",
      "      17\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      30\n",
      "     ]\n",
      "    ],\n",
      "    224\n",
      "   ],\n",
      "   [\n",
      "    3,\n",
      "    2902,\n",
      "    71,\n",
      "    122,\n",
      "    41,\n",
      "    [\n",
      "     [\n",
      "      4,\n",
      "      8\n",
      "     ],\n",
      "     [\n",
      "      6,\n",
      "      8\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      9\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      26\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ],\n",
      "   [\n",
      "    4,\n",
      "    2808,\n",
      "    71,\n",
      "    84,\n",
      "    40,\n",
      "    [\n",
      "     [\n",
      "      3,\n",
      "      29\n",
      "     ],\n",
      "     [\n",
      "      1,\n",
      "      35\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      48\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ],\n",
      "   [\n",
      "    5,\n",
      "    2744,\n",
      "    70,\n",
      "    22,\n",
      "    40,\n",
      "    [\n",
      "     [\n",
      "      3,\n",
      "      24\n",
      "     ],\n",
      "     [\n",
      "      1,\n",
      "      30\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      43\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ],\n",
      "   [\n",
      "    6,\n",
      "    3982,\n",
      "    3982,\n",
      "    50,\n",
      "    1,\n",
      "    [\n",
      "     [\n",
      "      2,\n",
      "      3\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      6\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      23\n",
      "     ]\n",
      "    ],\n",
      "    70\n",
      "   ],\n",
      "   [\n",
      "    7,\n",
      "    1471,\n",
      "    70,\n",
      "    122,\n",
      "    22,\n",
      "    [\n",
      "     [\n",
      "      8,\n",
      "      0\n",
      "     ]\n",
      "    ],\n",
      "    null\n",
      "   ],\n",
      "   [\n",
      "    8,\n",
      "    1783,\n",
      "    71,\n",
      "    22,\n",
      "    26,\n",
      "    [\n",
      "     [\n",
      "      0,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      2,\n",
      "      3\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      6\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      23\n",
      "     ]\n",
      "    ],\n",
      "    70\n",
      "   ],\n",
      "   [\n",
      "    9,\n",
      "    358,\n",
      "    70,\n",
      "    68,\n",
      "    6,\n",
      "    [\n",
      "     [\n",
      "      4,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      6,\n",
      "      0\n",
      "     ],\n",
      "     [\n",
      "      7,\n",
      "      1\n",
      "     ],\n",
      "     [\n",
      "      5,\n",
      "      18\n",
      "     ]\n",
      "    ],\n",
      "    132\n",
      "   ]\n",
      "  ],\n",
      "  [\n",
      "   [\n",
      "    10,\n",
      "    146\n",
      "   ],\n",
      "   [\n",
      "    11,\n",
      "    249\n",
      "   ],\n",
      "   [\n",
      "    13,\n",
      "    70\n",
      "   ]\n",
      "  ],\n",
      "  [\n",
      "   [\n",
      "    12,\n",
      "    null\n",
      "   ]\n",
      "  ]\n",
      " ],\n",
      " [\n",
      "  [\n",
      "   0,\n",
      "   71,\n",
      "   1,\n",
      "   13,\n",
      "   3\n",
      "  ],\n",
      "  [\n",
      "   1,\n",
      "   224,\n",
      "   2,\n",
      "   11,\n",
      "   13\n",
      "  ],\n",
      "  [\n",
      "   2,\n",
      "   70,\n",
      "   13,\n",
      "   10,\n",
      "   3\n",
      "  ],\n",
      "  [\n",
      "   3,\n",
      "   132,\n",
      "   4,\n",
      "   2,\n",
      "   6\n",
      "  ],\n",
      "  [\n",
      "   4,\n",
      "   132,\n",
      "   0,\n",
      "   10,\n",
      "   1\n",
      "  ],\n",
      "  [\n",
      "   5,\n",
      "   249,\n",
      "   11,\n",
      "   12,\n",
      "   1\n",
      "  ],\n",
      "  [\n",
      "   6,\n",
      "   132,\n",
      "   3,\n",
      "   10,\n",
      "   1\n",
      "  ],\n",
      "  [\n",
      "   7,\n",
      "   146,\n",
      "   10,\n",
      "   11,\n",
      "   17\n",
      "  ],\n",
      "  [\n",
      "   8,\n",
      "   Infinity,\n",
      "   7,\n",
      "   12,\n",
      "   1\n",
      "  ]\n",
      " ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def graph2list(filename):\n",
    "    \n",
    "    E,A = read_evac(\"evacsim-master/data/test_10_25_2_10.evac\")\n",
    "    \n",
    "    ########################## TRAITEMENT DES SOMMETS ##########################\n",
    "    \n",
    "    new_E = [] # Ensemble de sommets à évacuer\n",
    "    \n",
    "    for i_k in range(len(E)):\n",
    "        w_k, h_k, d_k = E[i_k]\n",
    "        p_k = math.ceil(w_k / h_k)\n",
    "        A_k = []\n",
    "        q_k = None\n",
    "        \n",
    "        k = [\n",
    "            i_k,  # Identifiant du sommet\n",
    "            w_k,  # Nombre de personnes à évacuer\n",
    "            h_k,  # Taux d'évacuation d'un sommet\n",
    "            d_k,  # Date à laquelle le sommet crame\n",
    "            p_k,  # Durée d'évacuation d'un sommet\n",
    "            A_k,  # Liste des sommets pour le chemin d'évacuation\n",
    "            q_k,  # Capacité d'un sommet\n",
    "        ]\n",
    "        \n",
    "        new_E.append(k)\n",
    "        \n",
    "    ########################## TRAITEMENT DES ARCS ##########################\n",
    "    \n",
    "    new_A = []\n",
    "    \n",
    "    for i_e in range (len(A)):\n",
    "        c_e, groups = A[i_e]\n",
    "        in_e = None\n",
    "        out_e = None\n",
    "        l_e = None\n",
    "\n",
    "        for i_k, b_e in groups:\n",
    "            \n",
    "            e = [    # Arc d'un chemin d'évacuation d'un sommet\n",
    "                i_e, # Identifiant de l'arc\n",
    "                b_e, # Date min de passage\n",
    "            ]\n",
    "            \n",
    "            k = new_E[i_k]\n",
    "            A_k = k[5]\n",
    "            \n",
    "            if len(A_k) == 0:\n",
    "                A_k.append(e)\n",
    "            else:\n",
    "                added = False\n",
    "                for i in range (len(A_k)):\n",
    "                    if A_k[i][1] > e[1]:\n",
    "                        A_k.insert(i,e)\n",
    "                        added = True\n",
    "                if added == False:\n",
    "                    A_k.append(e)\n",
    "            \n",
    "            k[5] = A_k\n",
    "            new_E[i_k] = k\n",
    "\n",
    "        e = [\n",
    "            i_e,     # Identifiant de l'arc\n",
    "            c_e,     # Capacité de l'arc en personnes par unité de temps\n",
    "            in_e,    # Identifiant du sommet entrant\n",
    "            out_e,   # Identifiant du sommet sortant\n",
    "            l_e,     # Longueur de l'arc\n",
    "        ]\n",
    "        \n",
    "        new_A.append(e)\n",
    "        \n",
    "    ####################### IDENIFICATION DES SOMMETS #######################\n",
    "    \n",
    "    # Cette partie va servir à trouver et compléter la liste des sommets\n",
    "    # intermédiaires et de sortie, tout en complétant les in/out des arcs\n",
    "        \n",
    "    new_T = [] # Ensemble de sommets de transfert\n",
    "    new_S = [] # Ensemble de sommets séurisés\n",
    "    \n",
    "    k_sommets = len(new_E)\n",
    "    k_arcs = []\n",
    "    \n",
    "    for k in new_E:\n",
    "        A_k = k[5]\n",
    "        parcours = k[0]\n",
    "        for i in range (len(A_k)):\n",
    "            e = new_A[A_k[i][0]]\n",
    "             \n",
    "            #On ajoute la capacité au sommet\n",
    "            if parcours < len(new_E):\n",
    "\n",
    "                #C'est un noeud de départ\n",
    "                if new_E[parcours][6] == None or new_E[parcours][6] > e[1]:\n",
    "                    new_E[parcours][6] = e[1]\n",
    "                    \n",
    "            else:\n",
    "    \n",
    "                #C'est un noeud intermédiaire\n",
    "                for j in range (len(new_T)):\n",
    "                    if new_T[j][0] == parcours:\n",
    "                        if new_T[j][1] == None or new_T[j][1] > e[1]:\n",
    "                            new_T[j][1] = e[1]\n",
    "                            \n",
    "            \n",
    "            if e[0] in k_arcs:\n",
    "                \n",
    "                #Arc connu donc rien à faire\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                #On ajoute le sommet d'entrée de l'arc\n",
    "                e[2] = parcours\n",
    "                \n",
    "                #On ajoute l'arc aux arc parcourus\n",
    "                k_arcs.append(e[0])\n",
    "                \n",
    "                #Contrôle de l'arc suivant\n",
    "                if i+1 < len(A_k):\n",
    "\n",
    "                    #Il y a bien un arc suivant, on a affaire à un sommet intermédiaire\n",
    "                    e_suiv = new_A[A_k[i+1][0]]\n",
    "                    \n",
    "                    #On peut donc connaître la longueur de l'arc\n",
    "                    e[4] = A_k[i+1][1] - A_k[i][1]\n",
    "\n",
    "                    if e_suiv[0] in k_arcs:\n",
    "\n",
    "                        #Arc connu donc on connait son entrée, donc celui de sortie de l'arc actuel\n",
    "                        e[3] = e_suiv[2]\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        #Arc inconnu donc on a découvert un nouveau sommet intermédiaire\n",
    "                        e[3] = k_sommets\n",
    "                        new_T.append([k_sommets,None])\n",
    "                        k_sommets += 1\n",
    "\n",
    "                    #On prépare le sommet de départ pour le prochain arc\n",
    "                    parcours = e[3]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    #Pas d'arc suivant donc on a atteint un sommet de sécurité\n",
    "                    e[3] = k_sommets\n",
    "                    new_S.append([k_sommets,None])\n",
    "                    k_sommets += 1\n",
    "                    \n",
    "                    #On ne peut donc pas connaître la longueur de l'arc, on la met arbitraitement à 1\n",
    "                    e[4] = VALEUR_ARBITRAIRE_ARC_SORTIE\n",
    "                        \n",
    "                #Mise à jour de e\n",
    "                new_A[e[0]] = e\n",
    "                \n",
    "    # TODO Bug sur le sommet 3 et arc 6 (qui a la même date au plus tôt que l'arc 4)\n",
    "    # On fait le choix de l'ignorer pour le moment, on a quand même un graphe utilisable\n",
    "    \n",
    "    ####################### CAS DES SOMMETS SANS ARCS  #######################\n",
    "            \n",
    "    for k in new_E:\n",
    "        A_k = k[5]\n",
    "        if len(A_k) == 0:\n",
    "            \n",
    "            #Nouvel arc pour relier le sommet\n",
    "            e = [\n",
    "                len(new_A), # Identifiant de l'arc\n",
    "                math.inf,   # Capacité de l'arc en personnes par unité de temps\n",
    "                k[0],       # Identifiant du sommet entrant\n",
    "                new_S[0][0],      # Identifiant du sommet sortant\n",
    "                VALEUR_ARBITRAIRE_ARC_SORTIE,        # Longueur de l'arc\n",
    "            ]\n",
    "            \n",
    "            A_k.append([e[0],0])\n",
    "            new_A.append(e)\n",
    "    \n",
    "    \n",
    "    ########################## TRAITEMENT DU GRAPHE ##########################\n",
    "    \n",
    "    X = [       # Ensemble des sommets du graphe\n",
    "        new_E,  # Ensemble de sommets à évacuer\n",
    "        new_T,  # Ensemble de sommets de transfert\n",
    "        new_S,  # Ensemble de sommets séurisés\n",
    "    ]\n",
    "    \n",
    "    G = [       # Notre graphe\n",
    "        X,      # Ensemble des sommets du graphe\n",
    "        new_A,  # Ensemble des arêtes du graphe\n",
    "    ]\n",
    "    \n",
    "    return G\n",
    "\n",
    "G_list = graph2list(\"projet/evacsim-master/data/test_10_25_2_10.evac\")\n",
    "\n",
    "print(json.dumps(G_list, indent=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, les données sont extraites pour générer le graphe qui sera donné en entrée de notre modèle de résolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, {'W': 4455, 'd': 68, 'eps': True, 'r': False, 'q': 132}), (1, {'W': 509, 'd': 22, 'eps': True, 'r': False, 'q': 71}), (2, {'W': 4584, 'd': 128, 'eps': True, 'r': False, 'q': 224}), (3, {'W': 2902, 'd': 122, 'eps': True, 'r': False, 'q': 132}), (4, {'W': 2808, 'd': 84, 'eps': True, 'r': False, 'q': 132}), (5, {'W': 2744, 'd': 22, 'eps': True, 'r': False, 'q': 132}), (6, {'W': 3982, 'd': 50, 'eps': True, 'r': False, 'q': 70}), (7, {'W': 1471, 'd': 122, 'eps': True, 'r': False, 'q': inf}), (8, {'W': 1783, 'd': 22, 'eps': True, 'r': False, 'q': 70}), (9, {'W': 358, 'd': 68, 'eps': True, 'r': False, 'q': 132}), (10, {'W': 0, 'd': 0, 'eps': False, 'r': False, 'q': 146}), (11, {'W': 0, 'd': 0, 'eps': False, 'r': False, 'q': 249}), (13, {'W': 0, 'd': 0, 'eps': False, 'r': False, 'q': 70}), (12, {'W': 0, 'd': 0, 'eps': False, 'r': True, 'q': inf})]\n",
      "[(1, 13, {'l': 3}), (2, 11, {'l': 13}), (13, 10, {'l': 3}), (4, 2, {'l': 6}), (0, 10, {'l': 1}), (11, 12, {'l': 1}), (3, 10, {'l': 1}), (10, 11, {'l': 17}), (7, 12, {'l': 1})]\n"
     ]
    }
   ],
   "source": [
    "def list2geosafe(G_list):\n",
    "    \n",
    "    nodes_state = []\n",
    "    edges_state = []\n",
    "    \n",
    "    for eps in G_list[0][0]:\n",
    "        nodes_state.append((eps[0], {'eps': True,  'r': False, 'W': eps[1], 'q': eps[6] if eps[6] is not None else math.inf, 'd': eps[3]}))\n",
    "        \n",
    "    for trans in G_list[0][1]:\n",
    "        nodes_state.append((trans[0], {'eps': False,  'r': False, 'W': 0, 'q': trans[1] if trans[1] is not None else math.inf, 'd': 0}))\n",
    "        \n",
    "    for r in G_list[0][2]:\n",
    "        nodes_state.append((r[0], {'eps': False,  'r': True, 'W': 0, 'q': r[1] if r[1] is not None else math.inf, 'd': 0}))\n",
    "        \n",
    "    for edge in G_list[1]:\n",
    "        edges_state.append((edge[2], edge[3], {'l' : edge[4]}))\n",
    "    \n",
    "    print(nodes_state)\n",
    "    print(edges_state)\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes_state)\n",
    "    G.add_edges_from(edges_state)\n",
    "    \n",
    "    return G\n",
    "        \n",
    "G = list2geosafe(G_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Partie 4 : 1ers Résultats \n",
    "\n",
    "TODO : \n",
    "- présenter les résultats ADA\n",
    "- comparer résultats ADA et GeoSafe\n",
    "\n",
    "## Partie 5 :  essai avec Contrainte cumulative\n",
    "\n",
    " \n",
    "https://www.ibm.com/support/knowledgecenter/en/SSSA5P_12.6.3/ilog.odms.cplex.help/refcppcplex/html/cumul_functions.html\n",
    "Exemples :  \n",
    "https://ibmdecisionoptimization.github.io/tutorials/html/Scheduling_Tutorial.html\n",
    "\n",
    "http://ibmdecisionoptimization.github.io/docplex-doc/cp/visu.rcpsp.py.html?fbclid=IwAR1ktKxQ09k7UBlBOxscZwFzNeiQ6_Qh62fnuRthOsZMQ45Eseche6xWzT8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.cp.model import CpoModel\n",
    "from docplex.cp.model import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG \n",
    "from config_duc import setup\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geosafe_model(l, q, eps, r, W, H, d,chemin):\n",
    "    '''       \n",
    "    Int  Matrix l: length path from i to j = G.l[i,j]. No path ij <--> G.l[i,j] = 0\n",
    "    Int  Array  q: capacity of node i <--> G.q[i]\n",
    "    Bool Array  eps: evacuation node \n",
    "    Bool Array  r: safe node\n",
    "    Int  Array  W: initial population at node i <--> W[i]\n",
    "    Int         H : Time span\n",
    "    Int  Array  d: deadline to leave the node\n",
    "    '''\n",
    "    \n",
    "    nb_node = q.shape[0] # ou len(q)\n",
    "    nodes = np.arange(nb_node) # id nodes, i.e [1,2,3,4, ...]\n",
    "    total_population = np.sum(W)\n",
    "    \n",
    "    t = !eps & !r # transition node\n",
    "\n",
    "    mdl = CpoModel(name='geosafe')\n",
    "    \n",
    "    # == Output ==\n",
    "    # starting date\n",
    "    #s = np.array([0,0,0,0,0,0])\n",
    "    #s = np.array( mdl.integer_var_list(nb_node, min=0, max = H, name=\"s\") ) # TODO : affiner max =H-w(v)/q(v)\n",
    "    \n",
    "    # evacuation rate aka. height of package\n",
    "    h = np.array([5,5,5,5,5,5])\n",
    "    itvs={}\n",
    "    for v in nodes[eps]:  \n",
    "        for u in chemin[v]: \n",
    "            duration = W[v]/h[v]\n",
    "            itvs[v,u]=mdl.interval_var(start=[int(l[v,u]), H], size= int(duration))\n",
    "    #h = np.array( mdl.integer_var_list(nb_node, min=0, max = 100, name=\"h\") ) # T0DO : affiner max =q[v]\n",
    "\n",
    "    # == Intermediate ==\n",
    "    # node flow of population for every node during [0,H]. It enables us to have phi for every transit node u.\n",
    "   # phi = np.matrix([\n",
    "   #         [ \n",
    "   #             mdl.integer_var(name='phi[%d,%d]'%(i,j)) for j in range(H) \n",
    "   #         ] for i in range(nb_node)\n",
    "   #     ])\n",
    "    \n",
    "    # ending date (leaving time) of node\n",
    "    #e = np.array( mdl.integer_var_list(nb_node, min=0, max = H, name= \"e\") ) # TODO : min c'est w[v]/q[v] \n",
    "    \n",
    "    # == Constraints ==\n",
    "    \n",
    "    # La date de départ des noeuds    \n",
    "    #for v in range(nb_node):\n",
    "    #    if eps[v]:       \n",
    "    #        mdl.add(\n",
    "    #            e[v] == s[v] + W[v]/h[v]\n",
    "    #        )\n",
    "    # evacuate everyone in evacuation node. On s'assure que tous les noeuds eps ont le temps d'être évacués\n",
    "    #for v in nodes[eps]:\n",
    "    #    mdl.add( h[v]*H >= W[v] ) \n",
    "    \n",
    "    # Flow at a node u = sum from all of its leaves node epsilon\n",
    "#     mdl.add_constraint(\n",
    "#         phi[u, t] == np.sum( phi[u, t - l[u,v] - s[eps]] ) \\\n",
    "#             for t in range(H)                                  \\\n",
    "#             for v in np.where(eps)                           \\\n",
    "#             for u in np.where(t)                             \n",
    "#     )\n",
    "\n",
    "    #  CONTRAINTE CUMULATIVE avec S fixé\n",
    "    #for v in nodes[eps]: # pour chaque resource on associe une tâche \n",
    "        # que l'on duplique ensuite sur chaque arc critique\n",
    "    #    phiarc=step_at(0, 0)\n",
    "    #    for u in chemin[v]: \n",
    "    #        phiarc += mdl.pulse((siuv, eiuv-siuv), h[v])       \n",
    "    #        mdl.add( phiarc <= q[u])\n",
    "            \n",
    "    #  CONTRAINTE CUMULATIVE avec h fixé\n",
    "    for v in nodes[eps]: # pour chaque resource on associe une tâche \n",
    "        # que l'on duplique ensuite sur chaque arc critique\n",
    "        phiarc=step_at(0, 0)\n",
    "        for u in chemin[v]: \n",
    "            phiarc += mdl.pulse(itvs[v,u], h[v])       \n",
    "            mdl.add( phiarc <= q[u])\n",
    "    \n",
    "    # Flow at a node does not excess capacity of arc\n",
    "    # TODO : deleted to see if cumulative constraint is working\n",
    "    #for t in range(H):\n",
    "     #   for u in nodes:\n",
    "     #       mdl.add(\n",
    "     #           phi[u,t] <= q[u]\n",
    "     #       )\n",
    "    \n",
    "    # Objective\n",
    "    mdl.add(\n",
    "    #    mdl.minimize(mdl.max(itvs[eps,] + W[eps]/h[eps] - d[eps]))\n",
    "         mdl.minimize(\n",
    "             mdl.max(\n",
    "                 mdl.end_of(\n",
    "                        itvs[v,(chemin[v][len(chemin[v])-2])])\n",
    "                 for v in nodes[eps] \n",
    "             )\n",
    "         )\n",
    "    )\n",
    "    \n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème de la contrainte cumulative est qu'elle attend des constantes (intger) et non des variables dans l'interval pulse. \n",
    "\n",
    "Je vais donc essayer de fixer ces valeurs :\n",
    "\n",
    "J'ai fixé S, starting date à 0 pour tout le monde. \n",
    "Cependant dans ma contrainte cumulative, il faudrait que fixe aussi la durée. Or, si je veux fixer la durée, je dois fixer le taux h (qui nous permet d'avoir la date de fin et donc la durée). Et si on fixe h en plus de fixer s, on a fixé toutes les variables que l'on cherche à définir. Donc on n'a plus de variable à déterminer ...\n",
    "\n",
    "\n",
    "```\n",
    "  siuv = s[v]+l[v,u]   \n",
    "  eiuv = e[v]+ l[v,u]   \n",
    "  phiarc += mdl.pulse((siuv, eiuv-siuv), h[v])\n",
    "            \n",
    "  mdl.add( phiarc <= q[u])\n",
    "```\n",
    "  \n",
    "avec e :\n",
    "```\n",
    "  e[v] == s[v] + W[v]/h[v]\n",
    "```\n",
    "\n",
    "SOLUTION : \n",
    "On fixe le taux d'évacuation H. Ainsi, on a une durée fixe et on veut déterminer l'heure de départ s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "global_d = 100 # TODO: delete this one, just for debug\n",
    "\n",
    "# TODO: Maybe we should use eps = W > 0, so that do not need to use 'eps' attribute?\n",
    "nodes_state = [\n",
    "    (1, {'eps': True,  'r': False, 'W': 5, 'd': global_d}),\n",
    "    (2, {'eps': True,  'r': False, 'W': 5, 'd': global_d}),\n",
    "    (3, {'eps': True,  'r': False, 'W': 5, 'd': global_d}),\n",
    "    (4, {'eps': False, 'r': False, 'W': 0, 'd': global_d}),\n",
    "    (5, {'eps': False, 'r': False, 'W': 0, 'd': global_d}),\n",
    "    (6, {'eps': False, 'r': True,  'W': 0, 'd': global_d})\n",
    "]\n",
    "\n",
    "edges_state = [\n",
    "    (1, 4, {'l' : 4}),\n",
    "    (2, 4, {'l' : 3}),\n",
    "    (4, 5, {'l' : 7}),\n",
    "    (3, 5, {'l' : 3}),\n",
    "    (5, 6, {'l' : 10})\n",
    "]\n",
    "chemin = [\n",
    "    [0,3,4,5],\n",
    "    [1,3,4,5],\n",
    "    [4,5]\n",
    "]\n",
    "\n",
    "G.add_nodes_from(nodes_state)\n",
    "G.add_edges_from(edges_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _node_attribute_(G, attribute='eps'):\n",
    "    '''\n",
    "    Author: Duc Hau :D\n",
    "    Return a numpy boolean array of attribute\n",
    "    '''\n",
    "    values_tmp = nx.get_node_attributes(G, attribute).values()\n",
    "    return np.array(list(values_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(_node_attribute_(G, attribute='W'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path length\n",
    "l = nx.floyd_warshall_numpy(G, weight='l')\n",
    "\n",
    "# Node capacities (shouldn't it be the path??)\n",
    "q = np.array([20,20,20,20,20,20])\n",
    "\n",
    "# If the node is in EPSILON (evacuating node)\n",
    "eps = _node_attribute_(G, 'eps')\n",
    "\n",
    "# If the node is in the ROOT (safe node)\n",
    "r = _node_attribute_(G, 'r')\n",
    "\n",
    "# Initial population\n",
    "W = _node_attribute_(G, 'W')\n",
    "\n",
    "# Time span\n",
    "H = 200\n",
    "\n",
    "# Deadline for evacutation\n",
    "d = _node_attribute_(G, 'd')\n",
    "\n",
    "# Solver configuration\n",
    "ctx = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nooooooodes [0 1 2]\n",
      "llll [[ 0. inf inf  4. 11. 21.]\n",
      " [inf  0. inf  3. 10. 20.]\n",
      " [inf inf  0. inf  3. 13.]\n",
      " [inf inf inf  0.  7. 17.]\n",
      " [inf inf inf inf  0. 10.]\n",
      " [inf inf inf inf inf  0.]]\n",
      "i ,  0\n",
      "chemin  [0, 3, 4, 5]\n",
      "0.0\n",
      "4.0\n",
      "11.0\n",
      "21.0\n",
      "i ,  1\n",
      "chemin  [1, 3, 4, 5]\n",
      "0.0\n",
      "3.0\n",
      "10.0\n",
      "20.0\n",
      "i ,  2\n",
      "chemin  [4, 5]\n",
      "3.0\n",
      "13.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_node = q.shape[0] # ou len(q)\n",
    "nodes = np.arange(nb_node) # id nodes, i.e [1,2,3,4, ...]\n",
    "print(\"nooooooodes\",nodes[eps])\n",
    "print(\"llll\",l)\n",
    "\n",
    "\n",
    "for i in nodes[eps]:\n",
    "    print(\"i , \",i)\n",
    "    print(\"chemin \", chemin[i])\n",
    "    for j in chemin[i] :\n",
    "        print(l[i,j])\n",
    "        \n",
    "        \n",
    "chemin[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = geosafe_model(l, q, eps, r, W, H, d, chemin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Solve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ipython-input-222-49d84b5e3cbd>:79(stream:19:11): Warning: Cumulative expression 'stepAt': height is zero, expression is zero everywhere.\n",
      "                                                              stepAt(0, 0)\n",
      "<ipython-input-222-49d84b5e3cbd>:79(stream:26:11): Warning: Cumulative expression 'stepAt': height is zero, expression is zero everywhere.\n",
      "                                                              stepAt(0, 0)\n",
      "<ipython-input-222-49d84b5e3cbd>:79(stream:33:11): Warning: Cumulative expression 'stepAt': height is zero, expression is zero everywhere.\n",
      "                                                              stepAt(0, 0)\n",
      " ! ----------------------------------------------------------------------------\n",
      " ! Minimization problem - 10 variables, 10 constraints\n",
      " ! Initial process time : 0.00s (0.00s extraction + 0.00s propagation)\n",
      " !  . Log search space  : 33.2 (before), 33.2 (after)\n",
      " !  . Memory usage      : 549.5 kB (before), 549.5 kB (after)\n",
      " ! Using parallel search with 4 workers.\n",
      " ! ----------------------------------------------------------------------------\n",
      " !          Best Branches  Non-fixed    W       Branch decision\n",
      "                        0         10                 -\n",
      " + New bound is 12\n",
      " *            12       10  0.00s        1      (gap is 0%)\n",
      " ! ----------------------------------------------------------------------------\n",
      " ! Search completed, 1 solution found.\n",
      " ! Best objective         : 12 (optimal - effective tol. is 0)\n",
      " ! Best bound             : 12\n",
      " ! Number of branches     : 12\n",
      " ! Number of fails        : 12\n",
      " ! Total memory usage     : 1.3 MB (1.2 MB CP Optimizer + 0.0 MB Concert)\n",
      " ! Time spent in solve    : 0.00s (0.00s engine + 0.00s extraction)\n",
      " ! Search speed (br. / s) : 1200.0\n",
      " ! ----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      " Result:\n",
      "-------------------------------------------------------------------------------\n",
      "Model constraints: 10, variables: integer: 0, interval: 10, sequence: 0\n",
      "Solve status: Optimal\n",
      "Search status: SearchCompleted, stop cause: SearchHasNotBeenStopped\n",
      "Solve time: 0.01 sec\n",
      "-------------------------------------------------------------------------------\n",
      "Objective values: (12,)\n",
      "          bounds: (12,)\n",
      "          gaps: (0.0,)\n",
      "_ITV_101: (start=0, end=1, size=1, length=1)\n",
      "_ITV_102: (start=4, end=5, size=1, length=1)\n",
      "_ITV_103: (start=11, end=12, size=1, length=1)\n",
      "_ITV_104: (start=21, end=22, size=1, length=1)\n",
      "_ITV_105: (start=0, end=1, size=1, length=1)\n",
      "_ITV_106: (start=3, end=4, size=1, length=1)\n",
      "_ITV_107: (start=10, end=11, size=1, length=1)\n",
      "_ITV_108: (start=20, end=21, size=1, length=1)\n",
      "_ITV_109: (start=3, end=4, size=1, length=1)\n",
      "_ITV_110: (start=13, end=14, size=1, length=1)\n"
     ]
    }
   ],
   "source": [
    "mdl.solve()\n",
    "sol = mdl.solve(Presolve='On', Workers='Auto')\n",
    "print(sol.get_solver_log())\n",
    "\n",
    "print('\\n\\n Result:')\n",
    "if sol.is_solution():\n",
    "    sol.print_solution()\n",
    "else:\n",
    "    print('Problem does not have solution')\n",
    "    sol.print_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
